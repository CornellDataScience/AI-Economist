/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
  for external in metadata.entry_points().get(self.group, []):
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-12-01 14:50:45,371	INFO resource_spec.py:212 -- Starting Ray with 11.82 GiB memory available for workers and up to 5.91 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2021-12-01 14:50:45,996	INFO services.py:1148 -- View the Ray dashboard at [1m[32mlocalhost:8265[39m[22m
2021-12-01 14:50:46,844 seed (final): 53782000
2021-12-01 14:50:46,990	INFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
2021-12-01 14:50:46,994	INFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
2021-12-01 14:51:47,314	INFO trainable.py:180 -- _setup took 60.322 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-12-01 14:51:47,314	INFO trainable.py:217 -- Getting current IP.
2021-12-01 14:51:47,315 Not restoring trainer...
2021-12-01 14:51:47,315 Restoring agents TF weights...
2021-12-01 14:51:47,882 loaded tf model weights:
	phase1/ckpts/agent.tf.weights.global-step-630000

2021-12-01 14:51:47,883 Starting with fresh planner TF weights.
2021-12-01 14:52:36,363 Iter 1: steps this-iter 6000 total 6000 -> 0/100000 episodes done
2021-12-01 14:52:36,369 custom_metrics: {}
date: 2021-12-01_14-52-36
done: false
episode_len_mean: .nan
episode_reward_max: .nan
episode_reward_mean: .nan
episode_reward_min: .nan
episodes_this_iter: 0
episodes_total: 0
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 8394.957
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.834976315498352
      entropy_coeff: 0.02500000037252903
      kl: 0.01187837403267622
      model: {}
      policy_loss: -0.0023172330111265182
      total_loss: 0.5013865232467651
      vf_explained_var: 0.815971851348877
      vf_loss: 10.991561889648438
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09571374952793121
      entropy_coeff: 2.0
      kl: 3.551874397089705e-05
      model: {}
      policy_loss: 2.7960166335105896e-05
      total_loss: 1.3069591522216797
      vf_explained_var: -0.0025140047073364258
      vf_loss: 29.967174530029297
  load_time_ms: 2037.895
  num_steps_sampled: 6000
  num_steps_trained: 6000
  sample_time_ms: 5420.893
  update_time_ms: 29300.174
iterations_since_restore: 1
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 43.334920634920636
  gpu_util_percent0: 0.933968253968254
  gpu_util_percent1: 0.00031746031746031746
  ram_util_percent: 77.05555555555556
  vram_util_percent0: 0.8752155368000722
  vram_util_percent1: 0.036424652165392896
pid: 82568
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf: {}
time_since_restore: 46.153390884399414
time_this_iter_s: 46.153390884399414
time_total_s: 46.153390884399414
timestamp: 1638388356
timesteps_since_restore: 6000
timesteps_this_iter: 6000
timesteps_total: 6000
training_iteration: 1

2021-12-01 14:52:44,503 Iter 2: steps this-iter 6000 total 12000 -> 0/100000 episodes done
2021-12-01 14:52:52,680 Iter 3: steps this-iter 6000 total 18000 -> 0/100000 episodes done
2021-12-01 14:53:00,761 Iter 4: steps this-iter 6000 total 24000 -> 0/100000 episodes done
2021-12-01 14:53:09,140 Iter 5: steps this-iter 6000 total 30000 -> 30/100000 episodes done
2021-12-01 14:53:09,146 custom_metrics: {}
date: 2021-12-01_14-53-09
done: false
episode_len_mean: 1000.0
episode_reward_max: 18.363177082088
episode_reward_mean: -79.95082758447458
episode_reward_min: -202.73544743614445
episodes_this_iter: 30
episodes_total: 30
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4564.589
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.4974594116210938
      entropy_coeff: 0.02500000037252903
      kl: 0.010936038568615913
      model: {}
      policy_loss: -0.00458131730556488
      total_loss: 0.31659838557243347
      vf_explained_var: -0.032534096390008926
      vf_loss: 7.172324180603027
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09582778811454773
      entropy_coeff: 1.9990999698638916
      kl: 6.173826477606781e-06
      model: {}
      policy_loss: 3.5664066672325134e-05
      total_loss: 1.4901975393295288
      vf_explained_var: 0.006875142455101013
      vf_loss: 33.63462448120117
  load_time_ms: 1022.476
  num_steps_sampled: 30000
  num_steps_trained: 30000
  sample_time_ms: 4109.712
  update_time_ms: 5872.682
iterations_since_restore: 5
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 58.57000000000001
  gpu_util_percent0: 0.951
  gpu_util_percent1: 0.0
  ram_util_percent: 87.80000000000001
  vram_util_percent0: 0.8752155368000725
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: -8.631845771716659
  p: 211.7222597035702
policy_reward_mean:
  a: -58.69476416946529
  p: 154.82822909338668
policy_reward_min:
  a: -100.91573630361705
  p: 82.70435404274097
sampler_perf:
  mean_env_wait_ms: 7.801625143477333
  mean_inference_ms: 8.292253216703138
  mean_processing_ms: 2.61716220206592
time_since_restore: 78.90513372421265
time_this_iter_s: 8.374660015106201
time_total_s: 78.90513372421265
timestamp: 1638388389
timesteps_since_restore: 30000
timesteps_this_iter: 6000
timesteps_total: 30000
training_iteration: 5

2021-12-01 14:53:09,460 >> Wrote dense logs to: phase2/dense_logs/logs_0000000000030000
2021-12-01 14:53:18,236 Iter 6: steps this-iter 6000 total 36000 -> 30/100000 episodes done
2021-12-01 14:53:26,349 Iter 7: steps this-iter 6000 total 42000 -> 30/100000 episodes done
2021-12-01 14:53:34,711 Iter 8: steps this-iter 6000 total 48000 -> 30/100000 episodes done
2021-12-01 14:53:44,021 Iter 9: steps this-iter 6000 total 54000 -> 30/100000 episodes done
2021-12-01 14:53:54,238 Iter 10: steps this-iter 6000 total 60000 -> 60/100000 episodes done
2021-12-01 14:53:54,245 custom_metrics: {}
date: 2021-12-01_14-53-54
done: false
episode_len_mean: 1000.0
episode_reward_max: 180.9988045596707
episode_reward_mean: 54.62136596209514
episode_reward_min: -91.23787942827053
episodes_this_iter: 30
episodes_total: 60
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4215.292
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.4054759740829468
      entropy_coeff: 0.02500000037252903
      kl: 0.002682702150195837
      model: {}
      policy_loss: -0.0006947512738406658
      total_loss: 0.475324809551239
      vf_explained_var: 0.05670060217380524
      vf_loss: 10.223129272460938
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09638749063014984
      entropy_coeff: 1.9979749917984009
      kl: 8.503403478243854e-06
      model: {}
      policy_loss: -8.308608084917068e-05
      total_loss: 1.7208925485610962
      vf_explained_var: 0.003008604049682617
      vf_loss: 38.27111053466797
  load_time_ms: 920.046
  num_steps_sampled: 60000
  num_steps_trained: 60000
  sample_time_ms: 4168.687
  update_time_ms: 2947.73
iterations_since_restore: 10
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 70.42727272727274
  gpu_util_percent0: 0.7927272727272728
  gpu_util_percent1: 0.0
  ram_util_percent: 89.24545454545455
  vram_util_percent0: 0.8752155368000725
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 21.658784744767413
  p: 217.8797757980724
policy_reward_mean:
  a: -26.558876590621594
  p: 160.85687232458164
policy_reward_min:
  a: -64.78541824814093
  p: 62.11198277322851
sampler_perf:
  mean_env_wait_ms: 7.919258589190918
  mean_inference_ms: 8.413298559371537
  mean_processing_ms: 2.8043514050266527
time_since_restore: 123.65628242492676
time_this_iter_s: 10.209663391113281
time_total_s: 123.65628242492676
timestamp: 1638388434
timesteps_since_restore: 60000
timesteps_this_iter: 6000
timesteps_total: 60000
training_iteration: 10

2021-12-01 14:54:03,696 Iter 11: steps this-iter 6000 total 66000 -> 60/100000 episodes done
2021-12-01 14:54:12,575 Iter 12: steps this-iter 6000 total 72000 -> 60/100000 episodes done
2021-12-01 14:54:21,419 Iter 13: steps this-iter 6000 total 78000 -> 60/100000 episodes done
2021-12-01 14:54:29,671 Iter 14: steps this-iter 6000 total 84000 -> 60/100000 episodes done
2021-12-01 14:54:37,854 Iter 15: steps this-iter 6000 total 90000 -> 90/100000 episodes done
2021-12-01 14:54:37,860 custom_metrics: {}
date: 2021-12-01_14-54-37
done: false
episode_len_mean: 1000.0
episode_reward_max: 215.05051539825908
episode_reward_mean: 123.8751705137167
episode_reward_min: 38.16458252345199
episodes_this_iter: 30
episodes_total: 90
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3845.844
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.3397631645202637
      entropy_coeff: 0.02500000037252903
      kl: 0.003439880209043622
      model: {}
      policy_loss: 0.0008225003257393837
      total_loss: 0.3107415437698364
      vf_explained_var: 0.17186398804187775
      vf_loss: 6.86826229095459
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09644728899002075
      entropy_coeff: 1.9968500137329102
      kl: 6.108545676397625e-06
      model: {}
      policy_loss: -0.00014121085405349731
      total_loss: 2.5925393104553223
      vf_explained_var: 0.002791374921798706
      vf_loss: 55.70542907714844
  load_time_ms: 808.542
  num_steps_sampled: 90000
  num_steps_trained: 90000
  sample_time_ms: 4143.432
  update_time_ms: 20.423
iterations_since_restore: 15
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.339999999999996
  gpu_util_percent0: 0.9430000000000002
  gpu_util_percent1: 0.0
  ram_util_percent: 88.91
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 27.023624381307396
  p: 215.2650917912752
policy_reward_mean:
  a: -7.144583787291293
  p: 152.45350566288255
policy_reward_min:
  a: -33.18678066526706
  p: 102.9812666355821
sampler_perf:
  mean_env_wait_ms: 7.848472339927152
  mean_inference_ms: 8.411423481796419
  mean_processing_ms: 2.8522609671287955
time_since_restore: 167.23820638656616
time_this_iter_s: 8.17873764038086
time_total_s: 167.23820638656616
timestamp: 1638388477
timesteps_since_restore: 90000
timesteps_this_iter: 6000
timesteps_total: 90000
training_iteration: 15

2021-12-01 14:54:46,056 Iter 16: steps this-iter 6000 total 96000 -> 90/100000 episodes done
2021-12-01 14:54:54,291 Iter 17: steps this-iter 6000 total 102000 -> 90/100000 episodes done
2021-12-01 14:55:02,478 Iter 18: steps this-iter 6000 total 108000 -> 90/100000 episodes done
2021-12-01 14:55:10,741 Iter 19: steps this-iter 6000 total 114000 -> 90/100000 episodes done
2021-12-01 14:55:18,756 Iter 20: steps this-iter 6000 total 120000 -> 120/100000 episodes done
2021-12-01 14:55:18,762 custom_metrics: {}
date: 2021-12-01_14-55-18
done: false
episode_len_mean: 1000.0
episode_reward_max: 127.43868784489335
episode_reward_mean: 35.54619291426577
episode_reward_min: -56.644927143810534
episodes_this_iter: 30
episodes_total: 120
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3741.672
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.3169605731964111
      entropy_coeff: 0.02500000037252903
      kl: 0.005085906479507685
      model: {}
      policy_loss: 0.0008073039352893829
      total_loss: 0.24419280886650085
      vf_explained_var: 0.21266575157642365
      vf_loss: 5.526190757751465
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09647070616483688
      entropy_coeff: 1.9957250356674194
      kl: 3.6698079384223092e-06
      model: {}
      policy_loss: 5.1952898502349854e-05
      total_loss: 2.233004331588745
      vf_explained_var: 0.003085717558860779
      vf_loss: 48.50962448120117
  load_time_ms: 782.892
  num_steps_sampled: 120000
  num_steps_trained: 120000
  sample_time_ms: 3889.298
  update_time_ms: 17.75
iterations_since_restore: 20
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.888888888888886
  gpu_util_percent0: 0.911111111111111
  gpu_util_percent1: 0.0
  ram_util_percent: 89.07777777777777
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766884
pid: 82568
policy_reward_max:
  a: 16.20790470966396
  p: 134.53875584468432
policy_reward_mean:
  a: -12.71414799522997
  p: 86.40278489518582
policy_reward_min:
  a: -43.44492240091002
  p: 37.622880894847995
sampler_perf:
  mean_env_wait_ms: 7.695521722781026
  mean_inference_ms: 8.180157172722607
  mean_processing_ms: 2.853734078312341
time_since_restore: 208.11056113243103
time_this_iter_s: 8.010181427001953
time_total_s: 208.11056113243103
timestamp: 1638388518
timesteps_since_restore: 120000
timesteps_this_iter: 6000
timesteps_total: 120000
training_iteration: 20

2021-12-01 14:55:27,523 Iter 21: steps this-iter 6000 total 126000 -> 120/100000 episodes done
2021-12-01 14:55:35,663 Iter 22: steps this-iter 6000 total 132000 -> 120/100000 episodes done
2021-12-01 14:55:43,924 Iter 23: steps this-iter 6000 total 138000 -> 120/100000 episodes done
2021-12-01 14:55:53,113 Iter 24: steps this-iter 6000 total 144000 -> 120/100000 episodes done
2021-12-01 14:56:04,836 Iter 25: steps this-iter 6000 total 150000 -> 150/100000 episodes done
2021-12-01 14:56:04,843 custom_metrics: {}
date: 2021-12-01_14-56-04
done: false
episode_len_mean: 1000.0
episode_reward_max: 194.40728793127238
episode_reward_mean: 73.30245768370378
episode_reward_min: -3.0895263554266634
episodes_this_iter: 30
episodes_total: 150
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4032.978
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.1190658807754517
      entropy_coeff: 0.02500000037252903
      kl: 0.002720734803006053
      model: {}
      policy_loss: -0.0002554766833782196
      total_loss: 0.1611528992652893
      vf_explained_var: 0.301310658454895
      vf_loss: 3.7877001762390137
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09662201255559921
      entropy_coeff: 1.9946000576019287
      kl: 4.301751232560491e-06
      model: {}
      policy_loss: -1.0128132998943329e-08
      total_loss: 2.8400824069976807
      vf_explained_var: -0.00047591328620910645
      vf_loss: 60.656089782714844
  load_time_ms: 792.851
  num_steps_sampled: 150000
  num_steps_trained: 150000
  sample_time_ms: 3819.558
  update_time_ms: 24.111
iterations_since_restore: 25
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 78.14285714285714
  gpu_util_percent0: 0.7328571428571429
  gpu_util_percent1: 0.0
  ram_util_percent: 90.4857142857143
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 22.578558055425468
  p: 178.33454786205897
policy_reward_mean:
  a: -5.352497736530959
  p: 94.71244862982795
policy_reward_min:
  a: -25.276900590616147
  p: 50.03468158489041
sampler_perf:
  mean_env_wait_ms: 7.682181485277853
  mean_inference_ms: 8.11633765598158
  mean_processing_ms: 2.8645143964676305
time_since_restore: 254.11494517326355
time_this_iter_s: 11.712798357009888
time_total_s: 254.11494517326355
timestamp: 1638388564
timesteps_since_restore: 150000
timesteps_this_iter: 6000
timesteps_total: 150000
training_iteration: 25

2021-12-01 14:56:14,561 Iter 26: steps this-iter 6000 total 156000 -> 150/100000 episodes done
2021-12-01 14:56:23,649 Iter 27: steps this-iter 6000 total 162000 -> 150/100000 episodes done
2021-12-01 14:56:32,087 Iter 28: steps this-iter 6000 total 168000 -> 150/100000 episodes done
2021-12-01 14:56:41,244 Iter 29: steps this-iter 6000 total 174000 -> 150/100000 episodes done
2021-12-01 14:56:49,366 Iter 30: steps this-iter 6000 total 180000 -> 180/100000 episodes done
2021-12-01 14:56:49,371 custom_metrics: {}
date: 2021-12-01_14-56-49
done: false
episode_len_mean: 1000.0
episode_reward_max: 137.35121823526873
episode_reward_mean: 42.4087218439572
episode_reward_min: -27.85677334597697
episodes_this_iter: 30
episodes_total: 180
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4103.837
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.985530436038971
      entropy_coeff: 0.02500000037252903
      kl: 0.0023363828659057617
      model: {}
      policy_loss: -0.0001413067802786827
      total_loss: 0.13199903070926666
      vf_explained_var: 0.3699479103088379
      vf_loss: 3.1355719566345215
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09665217250585556
      entropy_coeff: 1.9934749603271484
      kl: 5.475747911987128e-06
      model: {}
      policy_loss: -3.6945566534996033e-06
      total_loss: 2.0657830238342285
      vf_explained_var: 0.0011892765760421753
      vf_loss: 45.16920852661133
  load_time_ms: 838.099
  num_steps_sampled: 180000
  num_steps_trained: 180000
  sample_time_ms: 4055.545
  update_time_ms: 27.118
iterations_since_restore: 30
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 59.089999999999996
  gpu_util_percent0: 0.9330000000000002
  gpu_util_percent1: 0.0
  ram_util_percent: 90.23
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 28.23217479049709
  p: 126.9284903603329
policy_reward_mean:
  a: -6.249108289149256
  p: 67.40515500055447
policy_reward_min:
  a: -30.373454481806586
  p: 31.21044233752935
sampler_perf:
  mean_env_wait_ms: 7.717033723245189
  mean_inference_ms: 8.14373053915334
  mean_processing_ms: 2.891920437013177
time_since_restore: 298.545273065567
time_this_iter_s: 8.116153240203857
time_total_s: 298.545273065567
timestamp: 1638388609
timesteps_since_restore: 180000
timesteps_this_iter: 6000
timesteps_total: 180000
training_iteration: 30

2021-12-01 14:56:57,637 Iter 31: steps this-iter 6000 total 186000 -> 180/100000 episodes done
2021-12-01 14:57:05,769 Iter 32: steps this-iter 6000 total 192000 -> 180/100000 episodes done
2021-12-01 14:57:13,944 Iter 33: steps this-iter 6000 total 198000 -> 180/100000 episodes done
2021-12-01 14:57:22,136 Iter 34: steps this-iter 6000 total 204000 -> 180/100000 episodes done
2021-12-01 14:57:31,057 Iter 35: steps this-iter 6000 total 210000 -> 210/100000 episodes done
2021-12-01 14:57:31,062 custom_metrics: {}
date: 2021-12-01_14-57-31
done: false
episode_len_mean: 1000.0
episode_reward_max: 102.20904384885861
episode_reward_mean: 38.31716242322095
episode_reward_min: -19.111577069917026
episodes_this_iter: 30
episodes_total: 210
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3773.507
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.8960001468658447
      entropy_coeff: 0.02500000037252903
      kl: 0.002057787496596575
      model: {}
      policy_loss: 0.0004645022563636303
      total_loss: 0.09700879454612732
      vf_explained_var: 0.37557080388069153
      vf_loss: 2.3788857460021973
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09668135643005371
      entropy_coeff: 1.9923499822616577
      kl: 5.227166184340604e-06
      model: {}
      policy_loss: -6.988830864429474e-05
      total_loss: 1.9720799922943115
      vf_explained_var: 0.0008370727300643921
      vf_loss: 43.29545974731445
  load_time_ms: 818.08
  num_steps_sampled: 210000
  num_steps_trained: 210000
  sample_time_ms: 3981.106
  update_time_ms: 21.977
iterations_since_restore: 35
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 67.10000000000001
  gpu_util_percent0: 0.9081818181818182
  gpu_util_percent1: 0.0
  ram_util_percent: 91.68181818181819
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 24.170833031129884
  p: 98.8253582498162
policy_reward_mean:
  a: -3.664862203990872
  p: 52.97661123918454
policy_reward_min:
  a: -25.17826703142799
  p: 21.189285494012584
sampler_perf:
  mean_env_wait_ms: 7.659022989587739
  mean_inference_ms: 8.065346473229248
  mean_processing_ms: 2.898788722317564
time_since_restore: 340.20655632019043
time_this_iter_s: 8.91565465927124
time_total_s: 340.20655632019043
timestamp: 1638388651
timesteps_since_restore: 210000
timesteps_this_iter: 6000
timesteps_total: 210000
training_iteration: 35

2021-12-01 14:57:39,010 Iter 36: steps this-iter 6000 total 216000 -> 210/100000 episodes done
2021-12-01 14:57:47,366 Iter 37: steps this-iter 6000 total 222000 -> 210/100000 episodes done
2021-12-01 14:57:55,894 Iter 38: steps this-iter 6000 total 228000 -> 210/100000 episodes done
2021-12-01 14:58:05,226 Iter 39: steps this-iter 6000 total 234000 -> 210/100000 episodes done
2021-12-01 14:58:16,054 Iter 40: steps this-iter 6000 total 240000 -> 240/100000 episodes done
2021-12-01 14:58:16,060 custom_metrics: {}
date: 2021-12-01_14-58-16
done: false
episode_len_mean: 1000.0
episode_reward_max: 105.34405442256357
episode_reward_mean: 27.778367867024322
episode_reward_min: -18.892142842028235
episodes_this_iter: 30
episodes_total: 240
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3847.106
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.7731144428253174
      entropy_coeff: 0.02500000037252903
      kl: 0.002973769325762987
      model: {}
      policy_loss: -0.0012816078960895538
      total_loss: 0.1049853041768074
      vf_explained_var: 0.5481669306755066
      vf_loss: 2.5118956565856934
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09680834412574768
      entropy_coeff: 1.991225004196167
      kl: 2.555522542024846e-06
      model: {}
      policy_loss: -1.0788440704345703e-05
      total_loss: 2.42207407951355
      vf_explained_var: -9.757280349731445e-05
      vf_loss: 52.29703903198242
  load_time_ms: 800.959
  num_steps_sampled: 240000
  num_steps_trained: 240000
  sample_time_ms: 3979.649
  update_time_ms: 19.572
iterations_since_restore: 40
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 74.03333333333332
  gpu_util_percent0: 0.7174999999999999
  gpu_util_percent1: 0.0
  ram_util_percent: 93.00833333333333
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 16.75327413943416
  p: 97.83601775341805
policy_reward_mean:
  a: -4.805620059549071
  p: 47.00084810522071
policy_reward_min:
  a: -23.229878465009055
  p: 17.777767912001984
sampler_perf:
  mean_env_wait_ms: 7.6856424712848685
  mean_inference_ms: 8.128508461448929
  mean_processing_ms: 2.9125755480744973
time_since_restore: 385.1704604625702
time_this_iter_s: 10.823233366012573
time_total_s: 385.1704604625702
timestamp: 1638388696
timesteps_since_restore: 240000
timesteps_this_iter: 6000
timesteps_total: 240000
training_iteration: 40

2021-12-01 14:58:25,369 Iter 41: steps this-iter 6000 total 246000 -> 240/100000 episodes done
2021-12-01 14:58:33,712 Iter 42: steps this-iter 6000 total 252000 -> 240/100000 episodes done
2021-12-01 14:58:42,041 Iter 43: steps this-iter 6000 total 258000 -> 240/100000 episodes done
2021-12-01 14:58:50,241 Iter 44: steps this-iter 6000 total 264000 -> 240/100000 episodes done
2021-12-01 14:58:58,425 Iter 45: steps this-iter 6000 total 270000 -> 270/100000 episodes done
2021-12-01 14:58:58,430 custom_metrics: {}
date: 2021-12-01_14-58-58
done: false
episode_len_mean: 1000.0
episode_reward_max: 32.711439933571356
episode_reward_mean: 5.840820304223886
episode_reward_min: -25.441325970013377
episodes_this_iter: 30
episodes_total: 270
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3860.005
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.7061911821365356
      entropy_coeff: 0.02500000037252903
      kl: 0.0012298549991101027
      model: {}
      policy_loss: 1.3295095413923264e-05
      total_loss: 0.07089731097221375
      vf_explained_var: 0.30913710594177246
      vf_loss: 1.7707759141921997
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09672512114048004
      entropy_coeff: 1.9901000261306763
      kl: 5.2638397392001934e-06
      model: {}
      policy_loss: 1.1694617569446564e-05
      total_loss: 1.830978274345398
      vf_explained_var: -0.0023667067289352417
      vf_loss: 40.46917724609375
  load_time_ms: 806.324
  num_steps_sampled: 270000
  num_steps_trained: 270000
  sample_time_ms: 4028.704
  update_time_ms: 18.411
iterations_since_restore: 45
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 59.64000000000001
  gpu_util_percent0: 0.9359999999999999
  gpu_util_percent1: 0.0
  ram_util_percent: 92.43
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 24.349524620352167
  p: 44.914757049217194
policy_reward_mean:
  a: -6.113549964955625
  p: 30.295020164046452
policy_reward_min:
  a: -23.54107326875747
  p: 16.13357293903123
sampler_perf:
  mean_env_wait_ms: 7.667135260826755
  mean_inference_ms: 8.098826168051685
  mean_processing_ms: 2.911485914203435
time_since_restore: 427.50443863868713
time_this_iter_s: 8.172813892364502
time_total_s: 427.50443863868713
timestamp: 1638388738
timesteps_since_restore: 270000
timesteps_this_iter: 6000
timesteps_total: 270000
training_iteration: 45

2021-12-01 14:59:06,656 Iter 46: steps this-iter 6000 total 276000 -> 270/100000 episodes done
2021-12-01 14:59:14,848 Iter 47: steps this-iter 6000 total 282000 -> 270/100000 episodes done
2021-12-01 14:59:22,900 Iter 48: steps this-iter 6000 total 288000 -> 270/100000 episodes done
2021-12-01 14:59:31,087 Iter 49: steps this-iter 6000 total 294000 -> 270/100000 episodes done
2021-12-01 14:59:39,988 Iter 50: steps this-iter 6000 total 300000 -> 300/100000 episodes done
2021-12-01 14:59:39,997 custom_metrics: {}
date: 2021-12-01_14-59-39
done: false
episode_len_mean: 1000.0
episode_reward_max: 93.80903003876615
episode_reward_mean: 20.570716526182416
episode_reward_min: -15.251384944409791
episodes_this_iter: 30
episodes_total: 300
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3750.734
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6991881132125854
      entropy_coeff: 0.02500000037252903
      kl: 0.002728174440562725
      model: {}
      policy_loss: -0.0006809239275753498
      total_loss: 0.06111808493733406
      vf_explained_var: 0.5060970783233643
      vf_loss: 1.5855742692947388
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09673728793859482
      entropy_coeff: 1.9889750480651855
      kl: 3.346326593600679e-06
      model: {}
      policy_loss: 4.013627767562866e-05
      total_loss: 1.4811391830444336
      vf_explained_var: 0.0045362114906311035
      vf_loss: 33.47013854980469
  load_time_ms: 791.661
  num_steps_sampled: 300000
  num_steps_trained: 300000
  sample_time_ms: 3808.514
  update_time_ms: 17.722
iterations_since_restore: 50
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 65.47272727272727
  gpu_util_percent0: 0.8381818181818183
  gpu_util_percent1: 0.0
  ram_util_percent: 93.07272727272728
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 25.257528400991202
  p: 75.48188426483769
policy_reward_mean:
  a: -2.659542676970512
  p: 31.208887234064537
policy_reward_min:
  a: -22.064259753705464
  p: 14.39511143053618
sampler_perf:
  mean_env_wait_ms: 7.63806715864414
  mean_inference_ms: 8.058818456304392
  mean_processing_ms: 2.896255776631301
time_since_restore: 469.029221534729
time_this_iter_s: 8.896255254745483
time_total_s: 469.029221534729
timestamp: 1638388779
timesteps_since_restore: 300000
timesteps_this_iter: 6000
timesteps_total: 300000
training_iteration: 50

2021-12-01 14:59:48,140 Iter 51: steps this-iter 6000 total 306000 -> 300/100000 episodes done
2021-12-01 14:59:56,271 Iter 52: steps this-iter 6000 total 312000 -> 300/100000 episodes done
2021-12-01 15:00:04,462 Iter 53: steps this-iter 6000 total 318000 -> 300/100000 episodes done
2021-12-01 15:00:13,328 Iter 54: steps this-iter 6000 total 324000 -> 300/100000 episodes done
2021-12-01 15:00:26,104 Iter 55: steps this-iter 6000 total 330000 -> 330/100000 episodes done
2021-12-01 15:00:26,111 custom_metrics: {}
date: 2021-12-01_15-00-26
done: false
episode_len_mean: 1000.0
episode_reward_max: 65.65708514304465
episode_reward_mean: 12.370392426488689
episode_reward_min: -35.218001212245866
episodes_this_iter: 30
episodes_total: 330
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4125.059
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.7264475226402283
      entropy_coeff: 0.02500000037252903
      kl: 0.0015029632486402988
      model: {}
      policy_loss: -0.0004693465307354927
      total_loss: 0.06396233290433884
      vf_explained_var: 0.5307767987251282
      vf_loss: 1.6518571376800537
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09675642848014832
      entropy_coeff: 1.9878499507904053
      kl: 3.925747478206176e-06
      model: {}
      policy_loss: -7.258541882038116e-05
      total_loss: 1.2036993503570557
      vf_explained_var: 0.002674579620361328
      vf_loss: 27.92218589782715
  load_time_ms: 838.747
  num_steps_sampled: 330000
  num_steps_trained: 330000
  sample_time_ms: 3757.959
  update_time_ms: 17.792
iterations_since_restore: 55
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 79.75333333333333
  gpu_util_percent0: 0.7133333333333333
  gpu_util_percent1: 0.0
  ram_util_percent: 93.97333333333333
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 33.21510291610683
  p: 58.06144632660194
policy_reward_mean:
  a: -3.204985162954743
  p: 25.19033307830779
policy_reward_min:
  a: -20.961979934344125
  p: 7.332365136242255
sampler_perf:
  mean_env_wait_ms: 7.606669182857303
  mean_inference_ms: 8.013764689937632
  mean_processing_ms: 2.8979253903290063
time_since_restore: 515.0742950439453
time_this_iter_s: 12.76893162727356
time_total_s: 515.0742950439453
timestamp: 1638388826
timesteps_since_restore: 330000
timesteps_this_iter: 6000
timesteps_total: 330000
training_iteration: 55

2021-12-01 15:00:35,433 Iter 56: steps this-iter 6000 total 336000 -> 330/100000 episodes done
2021-12-01 15:00:44,166 Iter 57: steps this-iter 6000 total 342000 -> 330/100000 episodes done
2021-12-01 15:00:52,368 Iter 58: steps this-iter 6000 total 348000 -> 330/100000 episodes done
2021-12-01 15:01:00,517 Iter 59: steps this-iter 6000 total 354000 -> 330/100000 episodes done
2021-12-01 15:01:08,729 Iter 60: steps this-iter 6000 total 360000 -> 360/100000 episodes done
2021-12-01 15:01:08,736 custom_metrics: {}
date: 2021-12-01_15-01-08
done: false
episode_len_mean: 1000.0
episode_reward_max: 60.72836527492494
episode_reward_mean: 11.830478785365948
episode_reward_min: -23.006458887540372
episodes_this_iter: 30
episodes_total: 360
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4150.984
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.741432785987854
      entropy_coeff: 0.02500000037252903
      kl: 0.0027213909197598696
      model: {}
      policy_loss: -0.0006480561569333076
      total_loss: 0.03657355159521103
      vf_explained_var: 0.5110827088356018
      vf_loss: 1.115148663520813
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09669701009988785
      entropy_coeff: 1.9867249727249146
      kl: 2.1547259621002013e-06
      model: {}
      policy_loss: 2.3263506591320038e-05
      total_loss: 1.0767756700515747
      vf_explained_var: 0.011147662997245789
      vf_loss: 25.377256393432617
  load_time_ms: 838.901
  num_steps_sampled: 360000
  num_steps_trained: 360000
  sample_time_ms: 3838.913
  update_time_ms: 18.292
iterations_since_restore: 60
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 56.75
  gpu_util_percent0: 0.898
  gpu_util_percent1: 0.0
  ram_util_percent: 92.66999999999999
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 24.759831451457437
  p: 48.09864758892444
policy_reward_mean:
  a: -4.281273304828699
  p: 28.955572004680803
policy_reward_min:
  a: -19.98803518840878
  p: 13.999123178047991
sampler_perf:
  mean_env_wait_ms: 7.601585788958317
  mean_inference_ms: 8.004463865595207
  mean_processing_ms: 2.905043837024389
time_since_restore: 557.6675798892975
time_this_iter_s: 8.207961320877075
time_total_s: 557.6675798892975
timestamp: 1638388868
timesteps_since_restore: 360000
timesteps_this_iter: 6000
timesteps_total: 360000
training_iteration: 60

2021-12-01 15:01:16,970 Iter 61: steps this-iter 6000 total 366000 -> 360/100000 episodes done
2021-12-01 15:01:25,142 Iter 62: steps this-iter 6000 total 372000 -> 360/100000 episodes done
2021-12-01 15:01:33,319 Iter 63: steps this-iter 6000 total 378000 -> 360/100000 episodes done
2021-12-01 15:01:41,462 Iter 64: steps this-iter 6000 total 384000 -> 360/100000 episodes done
2021-12-01 15:01:50,655 Iter 65: steps this-iter 6000 total 390000 -> 390/100000 episodes done
2021-12-01 15:01:50,660 custom_metrics: {}
date: 2021-12-01_15-01-50
done: false
episode_len_mean: 1000.0
episode_reward_max: 64.63088850708294
episode_reward_mean: 2.925772408807765
episode_reward_min: -35.4619258140219
episodes_this_iter: 30
episodes_total: 390
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3758.988
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6899651288986206
      entropy_coeff: 0.02500000037252903
      kl: 0.002128251828253269
      model: {}
      policy_loss: -0.0005809376016259193
      total_loss: 0.05202223360538483
      vf_explained_var: 0.4853741228580475
      vf_loss: 1.3970458507537842
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09683821350336075
      entropy_coeff: 1.9855999946594238
      kl: 4.720156994153513e-06
      model: {}
      policy_loss: 1.4978460967540741e-05
      total_loss: 0.7027722597122192
      vf_explained_var: 0.02149549126625061
      vf_loss: 17.90078353881836
  load_time_ms: 800.725
  num_steps_sampled: 390000
  num_steps_trained: 390000
  sample_time_ms: 3839.707
  update_time_ms: 22.528
iterations_since_restore: 65
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 68.0
  gpu_util_percent0: 0.7754545454545455
  gpu_util_percent1: 0.0
  ram_util_percent: 93.27272727272727
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 25.839546541089568
  p: 47.03147045475913
policy_reward_mean:
  a: -5.230895346325368
  p: 23.849353794109295
policy_reward_min:
  a: -18.609753958581507
  p: 6.800832671831696
sampler_perf:
  mean_env_wait_ms: 7.585345977753081
  mean_inference_ms: 7.977368578991393
  mean_processing_ms: 2.8991356203593526
time_since_restore: 599.5107820034027
time_this_iter_s: 9.18900728225708
time_total_s: 599.5107820034027
timestamp: 1638388910
timesteps_since_restore: 390000
timesteps_this_iter: 6000
timesteps_total: 390000
training_iteration: 65

2021-12-01 15:01:59,072 Iter 66: steps this-iter 6000 total 396000 -> 390/100000 episodes done
2021-12-01 15:02:07,399 Iter 67: steps this-iter 6000 total 402000 -> 390/100000 episodes done
2021-12-01 15:02:16,198 Iter 68: steps this-iter 6000 total 408000 -> 390/100000 episodes done
2021-12-01 15:02:25,828 Iter 69: steps this-iter 6000 total 414000 -> 390/100000 episodes done
2021-12-01 15:02:37,014 Iter 70: steps this-iter 6000 total 420000 -> 420/100000 episodes done
2021-12-01 15:02:37,021 custom_metrics: {}
date: 2021-12-01_15-02-37
done: false
episode_len_mean: 1000.0
episode_reward_max: 39.03717959854156
episode_reward_mean: 13.262444220640338
episode_reward_min: -11.670416737049624
episodes_this_iter: 30
episodes_total: 420
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3887.202
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6372425556182861
      entropy_coeff: 0.02500000037252903
      kl: 0.002340540988370776
      model: {}
      policy_loss: -0.0007432699203491211
      total_loss: 0.044602684676647186
      vf_explained_var: 0.431596577167511
      vf_loss: 1.225540280342102
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09690447151660919
      entropy_coeff: 1.984475016593933
      kl: 2.9028913104411913e-06
      model: {}
      policy_loss: -1.5515834093093872e-06
      total_loss: 0.45899033546447754
      vf_explained_var: -0.02365870773792267
      vf_loss: 13.025927543640137
  load_time_ms: 840.429
  num_steps_sampled: 420000
  num_steps_trained: 420000
  sample_time_ms: 4044.775
  update_time_ms: 22.978
iterations_since_restore: 70
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 78.91666666666667
  gpu_util_percent0: 0.6516666666666667
  gpu_util_percent1: 0.0025
  ram_util_percent: 94.20833333333333
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 32.840753519240955
  p: 37.695765770242645
policy_reward_mean:
  a: -1.9048758944680364
  p: 20.881947798512524
policy_reward_min:
  a: -15.720706355643282
  p: 7.993965454600255
sampler_perf:
  mean_env_wait_ms: 7.63462589567163
  mean_inference_ms: 8.04697776060429
  mean_processing_ms: 2.9122166022503317
time_since_restore: 645.8355941772461
time_this_iter_s: 11.179890871047974
time_total_s: 645.8355941772461
timestamp: 1638388957
timesteps_since_restore: 420000
timesteps_this_iter: 6000
timesteps_total: 420000
training_iteration: 70

2021-12-01 15:02:46,255 Iter 71: steps this-iter 6000 total 426000 -> 420/100000 episodes done
2021-12-01 15:02:54,347 Iter 72: steps this-iter 6000 total 432000 -> 420/100000 episodes done
2021-12-01 15:03:02,580 Iter 73: steps this-iter 6000 total 438000 -> 420/100000 episodes done
2021-12-01 15:03:10,824 Iter 74: steps this-iter 6000 total 444000 -> 420/100000 episodes done
2021-12-01 15:03:19,028 Iter 75: steps this-iter 6000 total 450000 -> 450/100000 episodes done
2021-12-01 15:03:19,033 custom_metrics: {}
date: 2021-12-01_15-03-19
done: false
episode_len_mean: 1000.0
episode_reward_max: 31.623465868894346
episode_reward_mean: 6.039088753577176
episode_reward_min: -14.240156483347414
episodes_this_iter: 30
episodes_total: 450
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3914.037
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6130647659301758
      entropy_coeff: 0.02500000037252903
      kl: 0.0028462375048547983
      model: {}
      policy_loss: 0.0010459115728735924
      total_loss: 0.04211210831999779
      vf_explained_var: 0.5201573371887207
      vf_loss: 1.1278562545776367
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09683682024478912
      entropy_coeff: 1.9833500385284424
      kl: 4.007874395028921e-06
      model: {}
      policy_loss: -1.4061108231544495e-05
      total_loss: 0.24559244513511658
      vf_explained_var: 0.026408135890960693
      vf_loss: 8.753355979919434
  load_time_ms: 818.516
  num_steps_sampled: 450000
  num_steps_trained: 450000
  sample_time_ms: 4065.016
  update_time_ms: 17.136
iterations_since_restore: 75
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 56.89
  gpu_util_percent0: 0.8870000000000001
  gpu_util_percent1: 0.0
  ram_util_percent: 92.73999999999998
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 21.395245657814552
  p: 25.636988148472856
policy_reward_mean:
  a: -2.4112289958249478
  p: 15.684004736877009
policy_reward_min:
  a: -15.512940764174838
  p: 7.302475994151356
sampler_perf:
  mean_env_wait_ms: 7.615355290595848
  mean_inference_ms: 8.021889059680772
  mean_processing_ms: 2.913856270064106
time_since_restore: 687.8153786659241
time_this_iter_s: 8.198705673217773
time_total_s: 687.8153786659241
timestamp: 1638388999
timesteps_since_restore: 450000
timesteps_this_iter: 6000
timesteps_total: 450000
training_iteration: 75

2021-12-01 15:03:27,134 Iter 76: steps this-iter 6000 total 456000 -> 450/100000 episodes done
2021-12-01 15:03:35,295 Iter 77: steps this-iter 6000 total 462000 -> 450/100000 episodes done
2021-12-01 15:03:43,458 Iter 78: steps this-iter 6000 total 468000 -> 450/100000 episodes done
2021-12-01 15:03:51,996 Iter 79: steps this-iter 6000 total 474000 -> 450/100000 episodes done
2021-12-01 15:04:00,480 Iter 80: steps this-iter 6000 total 480000 -> 480/100000 episodes done
2021-12-01 15:04:00,487 custom_metrics: {}
date: 2021-12-01_15-04-00
done: false
episode_len_mean: 1000.0
episode_reward_max: 33.38478995116347
episode_reward_mean: 7.451722639299529
episode_reward_min: -9.298112577961737
episodes_this_iter: 30
episodes_total: 480
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3762.47
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5567313432693481
      entropy_coeff: 0.02500000037252903
      kl: 0.0012112713884562254
      model: {}
      policy_loss: -0.0003624632954597473
      total_loss: 0.039848752319812775
      vf_explained_var: 0.46424511075019836
      vf_loss: 1.082589864730835
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09683497995138168
      entropy_coeff: 1.982224941253662
      kl: 2.938586476375349e-06
      model: {}
      policy_loss: 3.795698285102844e-05
      total_loss: 0.1161760687828064
      vf_explained_var: 0.04389098286628723
      vf_loss: 6.161736488342285
  load_time_ms: 775.798
  num_steps_sampled: 480000
  num_steps_trained: 480000
  sample_time_ms: 3768.851
  update_time_ms: 16.355
iterations_since_restore: 80
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 61.20000000000001
  gpu_util_percent0: 0.8869999999999999
  gpu_util_percent1: 0.0
  ram_util_percent: 93.22
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 38.918333218541655
  p: 23.52990983651296
policy_reward_mean:
  a: -2.0562063452529014
  p: 15.676548020311229
policy_reward_min:
  a: -14.732893556847838
  p: 8.185124321671799
sampler_perf:
  mean_env_wait_ms: 7.595450921403645
  mean_inference_ms: 7.990877262227768
  mean_processing_ms: 2.9082136104706047
time_since_restore: 729.2336316108704
time_this_iter_s: 8.475806713104248
time_total_s: 729.2336316108704
timestamp: 1638389040
timesteps_since_restore: 480000
timesteps_this_iter: 6000
timesteps_total: 480000
training_iteration: 80

2021-12-01 15:04:08,754 Iter 81: steps this-iter 6000 total 486000 -> 480/100000 episodes done
2021-12-01 15:04:16,791 Iter 82: steps this-iter 6000 total 492000 -> 480/100000 episodes done
2021-12-01 15:04:25,365 Iter 83: steps this-iter 6000 total 498000 -> 480/100000 episodes done
2021-12-01 15:04:34,511 Iter 84: steps this-iter 6000 total 504000 -> 480/100000 episodes done
2021-12-01 15:04:45,416 Iter 85: steps this-iter 6000 total 510000 -> 510/100000 episodes done
2021-12-01 15:04:45,423 custom_metrics: {}
date: 2021-12-01_15-04-45
done: false
episode_len_mean: 1000.0
episode_reward_max: 39.04622636770247
episode_reward_mean: 2.031305986985809
episode_reward_min: -21.383930843172507
episodes_this_iter: 30
episodes_total: 510
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3804.966
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6332226991653442
      entropy_coeff: 0.02500000037252903
      kl: 0.0033259873744100332
      model: {}
      policy_loss: 0.0009459098801016808
      total_loss: 0.04221269488334656
      vf_explained_var: 0.5521370768547058
      vf_loss: 1.1419470310211182
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09686549752950668
      entropy_coeff: 1.9810999631881714
      kl: 2.9998768695804756e-06
      model: {}
      policy_loss: -4.025967791676521e-05
      total_loss: 0.03288712725043297
      vf_explained_var: 0.022403568029403687
      vf_loss: 4.496552467346191
  load_time_ms: 864.827
  num_steps_sampled: 510000
  num_steps_trained: 510000
  sample_time_ms: 3926.467
  update_time_ms: 17.483
iterations_since_restore: 85
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 76.81666666666668
  gpu_util_percent0: 0.7374999999999999
  gpu_util_percent1: 0.0
  ram_util_percent: 93.75000000000001
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 31.628138149407903
  p: 20.93013464310289
policy_reward_mean:
  a: -2.409205589340414
  p: 11.66812834434753
policy_reward_min:
  a: -14.305783925269726
  p: 2.3783944323957344
sampler_perf:
  mean_env_wait_ms: 7.603863425608501
  mean_inference_ms: 8.000218594090377
  mean_processing_ms: 2.9183762902276515
time_since_restore: 774.134735584259
time_this_iter_s: 10.8977210521698
time_total_s: 774.134735584259
timestamp: 1638389085
timesteps_since_restore: 510000
timesteps_this_iter: 6000
timesteps_total: 510000
training_iteration: 85

2021-12-01 15:04:54,640 Iter 86: steps this-iter 6000 total 516000 -> 510/100000 episodes done
2021-12-01 15:05:03,487 Iter 87: steps this-iter 6000 total 522000 -> 510/100000 episodes done
2021-12-01 15:05:11,659 Iter 88: steps this-iter 6000 total 528000 -> 510/100000 episodes done
2021-12-01 15:05:19,769 Iter 89: steps this-iter 6000 total 534000 -> 510/100000 episodes done
2021-12-01 15:05:27,926 Iter 90: steps this-iter 6000 total 540000 -> 540/100000 episodes done
2021-12-01 15:05:27,932 custom_metrics: {}
date: 2021-12-01_15-05-27
done: false
episode_len_mean: 1000.0
episode_reward_max: 49.8226580697103
episode_reward_mean: 12.642344062483266
episode_reward_min: -33.127764019026436
episodes_this_iter: 30
episodes_total: 540
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3828.659
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5904209613800049
      entropy_coeff: 0.02500000037252903
      kl: 0.0013071600114926696
      model: {}
      policy_loss: -0.0003144852817058563
      total_loss: 0.05271890386939049
      vf_explained_var: 0.4957132339477539
      vf_loss: 1.3558785915374756
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09687693417072296
      entropy_coeff: 1.9799749851226807
      kl: 4.40241456090007e-06
      model: {}
      policy_loss: -2.7993693947792053e-05
      total_loss: -0.004391457885503769
      vf_explained_var: 0.02641308307647705
      vf_loss: 3.749009132385254
  load_time_ms: 873.487
  num_steps_sampled: 540000
  num_steps_trained: 540000
  sample_time_ms: 3999.528
  update_time_ms: 17.437
iterations_since_restore: 90
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.75
  gpu_util_percent0: 0.953
  gpu_util_percent1: 0.0
  ram_util_percent: 92.81
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 48.16091219853556
  p: 29.237544762524195
policy_reward_mean:
  a: -0.6312114830244131
  p: 15.167189994581008
policy_reward_min:
  a: -16.327584949883384
  p: 2.4892662560708865
sampler_perf:
  mean_env_wait_ms: 7.598581291659154
  mean_inference_ms: 7.994337417266019
  mean_processing_ms: 2.9191703696433082
time_since_restore: 816.6006453037262
time_this_iter_s: 8.151345252990723
time_total_s: 816.6006453037262
timestamp: 1638389127
timesteps_since_restore: 540000
timesteps_this_iter: 6000
timesteps_total: 540000
training_iteration: 90

2021-12-01 15:05:36,121 Iter 91: steps this-iter 6000 total 546000 -> 540/100000 episodes done
2021-12-01 15:05:44,358 Iter 92: steps this-iter 6000 total 552000 -> 540/100000 episodes done
2021-12-01 15:05:52,481 Iter 93: steps this-iter 6000 total 558000 -> 540/100000 episodes done
2021-12-01 15:06:00,887 Iter 94: steps this-iter 6000 total 564000 -> 540/100000 episodes done
2021-12-01 15:06:09,705 Iter 95: steps this-iter 6000 total 570000 -> 570/100000 episodes done
2021-12-01 15:06:09,713 custom_metrics: {}
date: 2021-12-01_15-06-09
done: false
episode_len_mean: 1000.0
episode_reward_max: 55.15064103612566
episode_reward_mean: 16.37300490627431
episode_reward_min: -15.511400058450093
episodes_this_iter: 30
episodes_total: 570
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3759.1
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.61182701587677
      entropy_coeff: 0.02500000037252903
      kl: 0.0016347009222954512
      model: {}
      policy_loss: 0.0010152109898626804
      total_loss: 0.04526708647608757
      vf_explained_var: 0.49757933616638184
      vf_loss: 1.1909511089324951
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.0968625545501709
      entropy_coeff: 1.97885000705719
      kl: 4.831986643694108e-06
      model: {}
      policy_loss: -2.461858093738556e-05
      total_loss: 0.012400743551552296
      vf_explained_var: 0.026877790689468384
      vf_loss: 4.082036972045898
  load_time_ms: 780.634
  num_steps_sampled: 570000
  num_steps_trained: 570000
  sample_time_ms: 3837.269
  update_time_ms: 25.666
iterations_since_restore: 95
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 62.309090909090905
  gpu_util_percent0: 0.8945454545454545
  gpu_util_percent1: 0.0
  ram_util_percent: 93.4909090909091
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 29.45886177342978
  p: 37.70703694640016
policy_reward_mean:
  a: -0.7575808178053248
  p: 19.403328177495673
policy_reward_min:
  a: -15.229900338785987
  p: 9.024103625174883
sampler_perf:
  mean_env_wait_ms: 7.586982871198598
  mean_inference_ms: 7.97973418615137
  mean_processing_ms: 2.9173569133603223
time_since_restore: 858.3430771827698
time_this_iter_s: 8.809605360031128
time_total_s: 858.3430771827698
timestamp: 1638389169
timesteps_since_restore: 570000
timesteps_this_iter: 6000
timesteps_total: 570000
training_iteration: 95

2021-12-01 15:06:17,892 Iter 96: steps this-iter 6000 total 576000 -> 570/100000 episodes done
2021-12-01 15:06:26,080 Iter 97: steps this-iter 6000 total 582000 -> 570/100000 episodes done
2021-12-01 15:06:34,504 Iter 98: steps this-iter 6000 total 588000 -> 570/100000 episodes done
2021-12-01 15:06:43,690 Iter 99: steps this-iter 6000 total 594000 -> 570/100000 episodes done
2021-12-01 15:06:54,188 Iter 100: steps this-iter 6000 total 600000 -> 600/100000 episodes done
2021-12-01 15:06:54,196 custom_metrics: {}
date: 2021-12-01_15-06-54
done: false
episode_len_mean: 1000.0
episode_reward_max: 42.38216501361796
episode_reward_mean: 2.459587023356212
episode_reward_min: -22.945544445684508
episodes_this_iter: 30
episodes_total: 600
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3775.227
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5773097276687622
      entropy_coeff: 0.02500000037252903
      kl: 0.002314249984920025
      model: {}
      policy_loss: -0.000125860795378685
      total_loss: 0.05168631672859192
      vf_explained_var: 0.3397117853164673
      vf_loss: 1.3248984813690186
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09684967249631882
      entropy_coeff: 1.9777250289916992
      kl: 1.4693491721118335e-06
      model: {}
      policy_loss: -1.9650906324386597e-06
      total_loss: 0.04200853407382965
      vf_explained_var: 0.026578247547149658
      vf_loss: 4.671050071716309
  load_time_ms: 886.538
  num_steps_sampled: 600000
  num_steps_trained: 600000
  sample_time_ms: 3912.924
  update_time_ms: 26.34
iterations_since_restore: 100
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 75.90833333333335
  gpu_util_percent0: 0.755
  gpu_util_percent1: 0.0
  ram_util_percent: 93.95
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 29.500883164068263
  p: 47.77380084029556
policy_reward_mean:
  a: -3.6028665219438185
  p: 16.87105311113153
policy_reward_min:
  a: -17.168512278308047
  p: 4.056936099062387
sampler_perf:
  mean_env_wait_ms: 7.587148675822741
  mean_inference_ms: 7.982669287422623
  mean_processing_ms: 2.9300601343757884
time_since_restore: 902.7919907569885
time_this_iter_s: 10.491612672805786
time_total_s: 902.7919907569885
timestamp: 1638389214
timesteps_since_restore: 600000
timesteps_this_iter: 6000
timesteps_total: 600000
training_iteration: 100

2021-12-01 15:06:54,557 >> Wrote dense logs to: phase2/dense_logs/logs_0000000000600000
2021-12-01 15:07:04,034 Iter 101: steps this-iter 6000 total 606000 -> 600/100000 episodes done
2021-12-01 15:07:13,325 Iter 102: steps this-iter 6000 total 612000 -> 600/100000 episodes done
2021-12-01 15:07:21,541 Iter 103: steps this-iter 6000 total 618000 -> 600/100000 episodes done
2021-12-01 15:07:29,643 Iter 104: steps this-iter 6000 total 624000 -> 600/100000 episodes done
2021-12-01 15:07:38,426 Iter 105: steps this-iter 6000 total 630000 -> 630/100000 episodes done
2021-12-01 15:07:38,431 custom_metrics: {}
date: 2021-12-01_15-07-38
done: false
episode_len_mean: 1000.0
episode_reward_max: 47.19982612052485
episode_reward_mean: 13.24571974163238
episode_reward_min: -11.127718740224598
episodes_this_iter: 30
episodes_total: 630
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3825.016
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6352470517158508
      entropy_coeff: 0.02500000037252903
      kl: 0.0027634359430521727
      model: {}
      policy_loss: 0.0005436278879642487
      total_loss: 0.04072817042469978
      vf_explained_var: 0.4738616645336151
      vf_loss: 1.1213144063949585
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.0969114899635315
      entropy_coeff: 1.9766000509262085
      kl: 6.197219590831082e-06
      model: {}
      policy_loss: -7.707532495260239e-05
      total_loss: 0.07128789275884628
      vf_explained_var: -0.0013051927089691162
      vf_loss: 5.258403778076172
  load_time_ms: 934.7
  num_steps_sampled: 630000
  num_steps_trained: 630000
  sample_time_ms: 4036.606
  update_time_ms: 17.613
iterations_since_restore: 105
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 60.07272727272727
  gpu_util_percent0: 0.8518181818181819
  gpu_util_percent1: 0.0
  ram_util_percent: 94.00000000000001
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 33.69510260941298
  p: 33.27262414538318
policy_reward_mean:
  a: -1.552074717442917
  p: 19.45401861140414
policy_reward_min:
  a: -15.419613403579703
  p: 8.736906432271931
sampler_perf:
  mean_env_wait_ms: 7.620471551974854
  mean_inference_ms: 7.970541262175188
  mean_processing_ms: 2.9291336217358057
time_since_restore: 946.6372444629669
time_this_iter_s: 8.779582977294922
time_total_s: 946.6372444629669
timestamp: 1638389258
timesteps_since_restore: 630000
timesteps_this_iter: 6000
timesteps_total: 630000
training_iteration: 105

2021-12-01 15:07:47,229 Iter 106: steps this-iter 6000 total 636000 -> 630/100000 episodes done
2021-12-01 15:07:56,346 Iter 107: steps this-iter 6000 total 642000 -> 630/100000 episodes done
2021-12-01 15:08:04,793 Iter 108: steps this-iter 6000 total 648000 -> 630/100000 episodes done
2021-12-01 15:08:13,905 Iter 109: steps this-iter 6000 total 654000 -> 630/100000 episodes done
2021-12-01 15:08:22,098 Iter 110: steps this-iter 6000 total 660000 -> 660/100000 episodes done
2021-12-01 15:08:22,103 custom_metrics: {}
date: 2021-12-01_15-08-22
done: false
episode_len_mean: 1000.0
episode_reward_max: 68.09800981997523
episode_reward_mean: 16.551137082732676
episode_reward_min: -20.22715242770979
episodes_this_iter: 30
episodes_total: 660
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3854.323
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6452869176864624
      entropy_coeff: 0.02500000037252903
      kl: 0.0013302448205649853
      model: {}
      policy_loss: 0.0007599871605634689
      total_loss: 0.04005345702171326
      vf_explained_var: 0.48077571392059326
      vf_loss: 1.1085128784179688
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09691460430622101
      entropy_coeff: 1.9754749536514282
      kl: 3.878144525515381e-06
      model: {}
      policy_loss: -1.720339059829712e-05
      total_loss: 0.10301462560892105
      vf_explained_var: 0.027684539556503296
      vf_loss: 5.889683723449707
  load_time_ms: 858.739
  num_steps_sampled: 660000
  num_steps_trained: 660000
  sample_time_ms: 4003.677
  update_time_ms: 16.66
iterations_since_restore: 110
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.220000000000006
  gpu_util_percent0: 0.893
  gpu_util_percent1: 0.0
  ram_util_percent: 93.78
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 31.617884695728293
  p: 44.78041513799637
policy_reward_mean:
  a: -0.8093633123620645
  p: 19.78859033218104
policy_reward_min:
  a: -17.02214885374617
  p: 5.630484484063038
sampler_perf:
  mean_env_wait_ms: 7.609848699221048
  mean_inference_ms: 7.981146109251716
  mean_processing_ms: 2.9250114940793996
time_since_restore: 990.2760257720947
time_this_iter_s: 8.186992645263672
time_total_s: 990.2760257720947
timestamp: 1638389302
timesteps_since_restore: 660000
timesteps_this_iter: 6000
timesteps_total: 660000
training_iteration: 110

2021-12-01 15:08:30,225 Iter 111: steps this-iter 6000 total 666000 -> 660/100000 episodes done
2021-12-01 15:08:38,686 Iter 112: steps this-iter 6000 total 672000 -> 660/100000 episodes done
2021-12-01 15:08:55,028 Iter 113: steps this-iter 6000 total 678000 -> 660/100000 episodes done
2021-12-01 15:09:03,272 Iter 114: steps this-iter 6000 total 684000 -> 660/100000 episodes done
2021-12-01 15:09:14,604 Iter 115: steps this-iter 6000 total 690000 -> 690/100000 episodes done
2021-12-01 15:09:14,609 custom_metrics: {}
date: 2021-12-01_15-09-14
done: false
episode_len_mean: 1000.0
episode_reward_max: 63.17197638065537
episode_reward_mean: 17.977477898710504
episode_reward_min: -15.395336284195013
episodes_this_iter: 30
episodes_total: 690
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4135.613
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5740046501159668
      entropy_coeff: 0.02500000037252903
      kl: 0.0014599186833947897
      model: {}
      policy_loss: -0.0006010225042700768
      total_loss: 0.05124638229608536
      vf_explained_var: 0.47699934244155884
      vf_loss: 1.3239504098892212
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09689272940158844
      entropy_coeff: 1.9743499755859375
      kl: 1.5971718312357552e-06
      model: {}
      policy_loss: 2.886168658733368e-05
      total_loss: 0.18689501285552979
      vf_explained_var: 0.022045224905014038
      vf_loss: 7.563325881958008
  load_time_ms: 1533.472
  num_steps_sampled: 690000
  num_steps_trained: 690000
  sample_time_ms: 3901.131
  update_time_ms: 16.404
iterations_since_restore: 115
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 65.54615384615384
  gpu_util_percent0: 0.8561538461538463
  gpu_util_percent1: 0.0
  ram_util_percent: 94.73076923076923
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.0364015976761075
pid: 82568
policy_reward_max:
  a: 31.014907370995246
  p: 43.291824214077515
policy_reward_mean:
  a: -1.583373019261569
  p: 24.310969975756873
policy_reward_min:
  a: -16.71421201852937
  p: 7.897694011628197
sampler_perf:
  mean_env_wait_ms: 7.606731756057276
  mean_inference_ms: 7.970699849284968
  mean_processing_ms: 2.9268384230298747
time_since_restore: 1042.7051088809967
time_this_iter_s: 11.327199220657349
time_total_s: 1042.7051088809967
timestamp: 1638389354
timesteps_since_restore: 690000
timesteps_this_iter: 6000
timesteps_total: 690000
training_iteration: 115

2021-12-01 15:09:23,485 Iter 116: steps this-iter 6000 total 696000 -> 690/100000 episodes done
2021-12-01 15:09:31,822 Iter 117: steps this-iter 6000 total 702000 -> 690/100000 episodes done
2021-12-01 15:09:40,036 Iter 118: steps this-iter 6000 total 708000 -> 690/100000 episodes done
2021-12-01 15:09:48,172 Iter 119: steps this-iter 6000 total 714000 -> 690/100000 episodes done
2021-12-01 15:09:56,270 Iter 120: steps this-iter 6000 total 720000 -> 720/100000 episodes done
2021-12-01 15:09:56,277 custom_metrics: {}
date: 2021-12-01_15-09-56
done: false
episode_len_mean: 1000.0
episode_reward_max: 39.36681787486522
episode_reward_mean: 14.514567858915656
episode_reward_min: -9.742992461372065
episodes_this_iter: 30
episodes_total: 720
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4044.845
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5363693833351135
      entropy_coeff: 0.02500000037252903
      kl: 0.0030224958900362253
      model: {}
      policy_loss: -8.049421012401581e-05
      total_loss: 0.04248065501451492
      vf_explained_var: 0.5977102518081665
      vf_loss: 1.1194076538085938
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09693870693445206
      entropy_coeff: 1.9732249975204468
      kl: 3.306484586573788e-06
      model: {}
      policy_loss: 2.2981315851211548e-05
      total_loss: 0.09445078670978546
      vf_explained_var: 0.021799176931381226
      vf_loss: 5.714194297790527
  load_time_ms: 1519.183
  num_steps_sampled: 720000
  num_steps_trained: 720000
  sample_time_ms: 3804.45
  update_time_ms: 16.265
iterations_since_restore: 120
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.566666666666656
  gpu_util_percent0: 0.9266666666666666
  gpu_util_percent1: 0.0
  ram_util_percent: 93.19999999999999
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610748
pid: 82568
policy_reward_max:
  a: 36.52034875246856
  p: 34.52809131630583
policy_reward_mean:
  a: -0.6949616976623235
  p: 17.294414649565034
policy_reward_min:
  a: -13.83229384384399
  p: 6.446668780646344
sampler_perf:
  mean_env_wait_ms: 7.59582436816695
  mean_inference_ms: 7.95661813144629
  mean_processing_ms: 2.9208647927156743
time_since_restore: 1084.3413565158844
time_this_iter_s: 8.093705892562866
time_total_s: 1084.3413565158844
timestamp: 1638389396
timesteps_since_restore: 720000
timesteps_this_iter: 6000
timesteps_total: 720000
training_iteration: 120

2021-12-01 15:10:04,548 Iter 121: steps this-iter 6000 total 726000 -> 720/100000 episodes done
2021-12-01 15:10:12,803 Iter 122: steps this-iter 6000 total 732000 -> 720/100000 episodes done
2021-12-01 15:10:21,222 Iter 123: steps this-iter 6000 total 738000 -> 720/100000 episodes done
2021-12-01 15:10:30,188 Iter 124: steps this-iter 6000 total 744000 -> 720/100000 episodes done
2021-12-01 15:10:38,244 Iter 125: steps this-iter 6000 total 750000 -> 750/100000 episodes done
2021-12-01 15:10:38,249 custom_metrics: {}
date: 2021-12-01_15-10-38
done: false
episode_len_mean: 1000.0
episode_reward_max: 40.879000299137914
episode_reward_mean: 20.197577553984736
episode_reward_min: -25.25993841328618
episodes_this_iter: 30
episodes_total: 750
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3720.103
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5554507970809937
      entropy_coeff: 0.02500000037252903
      kl: 0.003706294810399413
      model: {}
      policy_loss: -1.5929341316223145e-05
      total_loss: 0.037695854902267456
      vf_explained_var: 0.4569172263145447
      vf_loss: 1.0319609642028809
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.0969199538230896
      entropy_coeff: 1.972100019454956
      kl: 3.3194676234415965e-06
      model: {}
      policy_loss: -1.810304820537567e-05
      total_loss: 0.0925227627158165
      vf_explained_var: 0.029296323657035828
      vf_loss: 5.673534393310547
  load_time_ms: 822.597
  num_steps_sampled: 750000
  num_steps_trained: 750000
  sample_time_ms: 3774.535
  update_time_ms: 21.184
iterations_since_restore: 125
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 56.47777777777779
  gpu_util_percent0: 0.9044444444444445
  gpu_util_percent1: 0.0
  ram_util_percent: 93.17777777777778
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766884
pid: 82568
policy_reward_max:
  a: 30.472345414079562
  p: 32.22866370069962
policy_reward_mean:
  a: -0.021773047267460845
  p: 20.284669743054703
policy_reward_min:
  a: -14.658824304143305
  p: 3.7283831280368274
sampler_perf:
  mean_env_wait_ms: 7.5858953366169555
  mean_inference_ms: 7.942773503557743
  mean_processing_ms: 2.916221819678848
time_since_restore: 1126.2784304618835
time_this_iter_s: 8.05046820640564
time_total_s: 1126.2784304618835
timestamp: 1638389438
timesteps_since_restore: 750000
timesteps_this_iter: 6000
timesteps_total: 750000
training_iteration: 125

2021-12-01 15:10:46,637 Iter 126: steps this-iter 6000 total 756000 -> 750/100000 episodes done
2021-12-01 15:10:55,944 Iter 127: steps this-iter 6000 total 762000 -> 750/100000 episodes done
2021-12-01 15:11:06,435 Iter 128: steps this-iter 6000 total 768000 -> 750/100000 episodes done
2021-12-01 15:11:14,623 Iter 129: steps this-iter 6000 total 774000 -> 750/100000 episodes done
2021-12-01 15:11:23,895 Iter 130: steps this-iter 6000 total 780000 -> 780/100000 episodes done
2021-12-01 15:11:23,904 custom_metrics: {}
date: 2021-12-01_15-11-23
done: false
episode_len_mean: 1000.0
episode_reward_max: 52.0870620318521
episode_reward_mean: 19.67854376592962
episode_reward_min: -31.25497866350932
episodes_this_iter: 30
episodes_total: 780
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3865.022
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5446950793266296
      entropy_coeff: 0.02500000037252903
      kl: 0.0026643897872418165
      model: {}
      policy_loss: -0.0008938508108258247
      total_loss: 0.03603871166706085
      vf_explained_var: 0.6205780506134033
      vf_loss: 1.0109988451004028
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09690005332231522
      entropy_coeff: 1.9709750413894653
      kl: 1.7757058685674565e-06
      model: {}
      policy_loss: -2.0094215869903564e-05
      total_loss: 0.07127695530653
      vf_explained_var: 0.02738146483898163
      vf_loss: 5.245692253112793
  load_time_ms: 879.289
  num_steps_sampled: 780000
  num_steps_trained: 780000
  sample_time_ms: 3965.439
  update_time_ms: 21.871
iterations_since_restore: 130
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 67.95454545454545
  gpu_util_percent0: 0.8454545454545456
  gpu_util_percent1: 0.0
  ram_util_percent: 94.2
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 28.157855966001456
  p: 30.145372933359095
policy_reward_mean:
  a: 0.34113194082114967
  p: 18.314016002645133
policy_reward_min:
  a: -16.637208222464132
  p: 1.081047318849123
sampler_perf:
  mean_env_wait_ms: 7.592367603554398
  mean_inference_ms: 7.953497140362907
  mean_processing_ms: 2.930587614114294
time_since_restore: 1171.8464229106903
time_this_iter_s: 9.267462253570557
time_total_s: 1171.8464229106903
timestamp: 1638389483
timesteps_since_restore: 780000
timesteps_this_iter: 6000
timesteps_total: 780000
training_iteration: 130

2021-12-01 15:11:33,016 Iter 131: steps this-iter 6000 total 786000 -> 780/100000 episodes done
2021-12-01 15:11:41,218 Iter 132: steps this-iter 6000 total 792000 -> 780/100000 episodes done
2021-12-01 15:11:49,406 Iter 133: steps this-iter 6000 total 798000 -> 780/100000 episodes done
2021-12-01 15:11:57,722 Iter 134: steps this-iter 6000 total 804000 -> 780/100000 episodes done
2021-12-01 15:12:05,854 Iter 135: steps this-iter 6000 total 810000 -> 810/100000 episodes done
2021-12-01 15:12:05,858 custom_metrics: {}
date: 2021-12-01_15-12-05
done: false
episode_len_mean: 1000.0
episode_reward_max: 41.3827234233087
episode_reward_mean: 18.430559990128916
episode_reward_min: -6.0671185701935695
episodes_this_iter: 30
episodes_total: 810
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3882.795
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5463655591011047
      entropy_coeff: 0.02500000037252903
      kl: 0.002647584769874811
      model: {}
      policy_loss: 0.0011971546337008476
      total_loss: 0.046843890100717545
      vf_explained_var: 0.48800623416900635
      vf_loss: 1.18611741065979
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09683249890804291
      entropy_coeff: 1.969849944114685
      kl: 1.536099716759054e-06
      model: {}
      policy_loss: -1.001870259642601e-05
      total_loss: 0.059113964438438416
      vf_explained_var: 0.05832397937774658
      vf_loss: 4.997389793395996
  load_time_ms: 870.423
  num_steps_sampled: 810000
  num_steps_trained: 810000
  sample_time_ms: 3955.836
  update_time_ms: 18.177
iterations_since_restore: 135
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.10999999999999
  gpu_util_percent0: 0.945
  gpu_util_percent1: 0.0
  ram_util_percent: 93.32
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.0364288307915759
pid: 82568
policy_reward_max:
  a: 31.55815968686047
  p: 35.020949031131785
policy_reward_mean:
  a: 0.30800703059113216
  p: 17.198531867764494
policy_reward_min:
  a: -13.705162045631456
  p: 7.732049035096992
sampler_perf:
  mean_env_wait_ms: 7.583038947282701
  mean_inference_ms: 7.944239878738953
  mean_processing_ms: 2.9277253842328217
time_since_restore: 1213.7252101898193
time_this_iter_s: 8.127148389816284
time_total_s: 1213.7252101898193
timestamp: 1638389525
timesteps_since_restore: 810000
timesteps_this_iter: 6000
timesteps_total: 810000
training_iteration: 135

2021-12-01 15:12:14,017 Iter 136: steps this-iter 6000 total 816000 -> 810/100000 episodes done
2021-12-01 15:12:22,116 Iter 137: steps this-iter 6000 total 822000 -> 810/100000 episodes done
2021-12-01 15:12:30,376 Iter 138: steps this-iter 6000 total 828000 -> 810/100000 episodes done
2021-12-01 15:12:39,285 Iter 139: steps this-iter 6000 total 834000 -> 810/100000 episodes done
2021-12-01 15:12:47,442 Iter 140: steps this-iter 6000 total 840000 -> 840/100000 episodes done
2021-12-01 15:12:47,447 custom_metrics: {}
date: 2021-12-01_15-12-47
done: false
episode_len_mean: 1000.0
episode_reward_max: 50.15396551383887
episode_reward_mean: 18.721325405387226
episode_reward_min: -10.457730421331426
episodes_this_iter: 30
episodes_total: 840
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3730.867
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6039740443229675
      entropy_coeff: 0.02500000037252903
      kl: 0.00392730999737978
      model: {}
      policy_loss: 0.0009676134213805199
      total_loss: 0.030046433210372925
      vf_explained_var: 0.49842262268066406
      vf_loss: 0.8835634589195251
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09693045914173126
      entropy_coeff: 1.9687249660491943
      kl: 2.146690349036362e-06
      model: {}
      policy_loss: -1.1578202247619629e-05
      total_loss: 0.03960445150732994
      vf_explained_var: 0.013504952192306519
      vf_loss: 4.608908653259277
  load_time_ms: 799.206
  num_steps_sampled: 840000
  num_steps_trained: 840000
  sample_time_ms: 3781.265
  update_time_ms: 16.732
iterations_since_restore: 140
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 57.85000000000001
  gpu_util_percent0: 0.951
  gpu_util_percent1: 0.0
  ram_util_percent: 93.2
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 43.06539266978639
  p: 27.726338289623175
policy_reward_mean:
  a: 0.6604620507075861
  p: 16.07947720255704
policy_reward_min:
  a: -11.175273324692437
  p: 7.162165787976771
sampler_perf:
  mean_env_wait_ms: 7.575105082192192
  mean_inference_ms: 7.933026811684128
  mean_processing_ms: 2.9270852938814693
time_since_restore: 1255.285621881485
time_this_iter_s: 8.152726173400879
time_total_s: 1255.285621881485
timestamp: 1638389567
timesteps_since_restore: 840000
timesteps_this_iter: 6000
timesteps_total: 840000
training_iteration: 140

2021-12-01 15:12:55,953 Iter 141: steps this-iter 6000 total 846000 -> 840/100000 episodes done
2021-12-01 15:13:05,299 Iter 142: steps this-iter 6000 total 852000 -> 840/100000 episodes done
2021-12-01 15:13:17,618 Iter 143: steps this-iter 6000 total 858000 -> 840/100000 episodes done
2021-12-01 15:13:26,096 Iter 144: steps this-iter 6000 total 864000 -> 840/100000 episodes done
2021-12-01 15:13:39,898 Iter 145: steps this-iter 6000 total 870000 -> 870/100000 episodes done
2021-12-01 15:13:39,907 custom_metrics: {}
date: 2021-12-01_15-13-39
done: false
episode_len_mean: 1000.0
episode_reward_max: 46.07535501625794
episode_reward_mean: 19.071765747755137
episode_reward_min: -3.8445209815160983
episodes_this_iter: 30
episodes_total: 870
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3893.386
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5552750825881958
      entropy_coeff: 0.02500000037252903
      kl: 0.0026695430278778076
      model: {}
      policy_loss: 0.0006408030167222023
      total_loss: 0.02888086624443531
      vf_explained_var: 0.514324426651001
      vf_loss: 0.842438817024231
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09692747890949249
      entropy_coeff: 1.9675999879837036
      kl: 1.7730892523104558e-06
      model: {}
      policy_loss: 1.2114644050598145e-05
      total_loss: 0.03104776330292225
      vf_explained_var: 0.03352765738964081
      vf_loss: 4.435003280639648
  load_time_ms: 1540.548
  num_steps_sampled: 870000
  num_steps_trained: 870000
  sample_time_ms: 3931.506
  update_time_ms: 15.651
iterations_since_restore: 145
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 66.70625
  gpu_util_percent0: 0.794375
  gpu_util_percent1: 0.0
  ram_util_percent: 95.2875
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610748
pid: 82568
policy_reward_max:
  a: 33.550350675230256
  p: 25.692152191743915
policy_reward_mean:
  a: 0.6273781315053474
  p: 16.56225322173389
policy_reward_min:
  a: -13.78755340229487
  p: 3.6202750845751144
sampler_perf:
  mean_env_wait_ms: 7.584960137055035
  mean_inference_ms: 7.941244405495643
  mean_processing_ms: 2.931099012087317
time_since_restore: 1307.7065274715424
time_this_iter_s: 13.797642946243286
time_total_s: 1307.7065274715424
timestamp: 1638389619
timesteps_since_restore: 870000
timesteps_this_iter: 6000
timesteps_total: 870000
training_iteration: 145

2021-12-01 15:13:48,520 Iter 146: steps this-iter 6000 total 876000 -> 870/100000 episodes done
2021-12-01 15:13:56,787 Iter 147: steps this-iter 6000 total 882000 -> 870/100000 episodes done
2021-12-01 15:14:04,846 Iter 148: steps this-iter 6000 total 888000 -> 870/100000 episodes done
2021-12-01 15:14:13,014 Iter 149: steps this-iter 6000 total 894000 -> 870/100000 episodes done
2021-12-01 15:14:21,241 Iter 150: steps this-iter 6000 total 900000 -> 900/100000 episodes done
2021-12-01 15:14:21,246 custom_metrics: {}
date: 2021-12-01_15-14-21
done: false
episode_len_mean: 1000.0
episode_reward_max: 49.06385908669104
episode_reward_mean: 20.67450536457499
episode_reward_min: -1.5742853965229333
episodes_this_iter: 30
episodes_total: 900
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3914.485
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.588600218296051
      entropy_coeff: 0.02500000037252903
      kl: 0.0027964329347014427
      model: {}
      policy_loss: 0.0009539853781461716
      total_loss: 0.03408438339829445
      vf_explained_var: 0.587358295917511
      vf_loss: 0.956908106803894
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09689804911613464
      entropy_coeff: 1.966475009918213
      kl: 1.797672894099378e-06
      model: {}
      policy_loss: 2.3640692234039307e-05
      total_loss: 0.020639540627598763
      vf_explained_var: -0.0016587376594543457
      vf_loss: 4.223269462585449
  load_time_ms: 1547.491
  num_steps_sampled: 900000
  num_steps_trained: 900000
  sample_time_ms: 3876.982
  update_time_ms: 16.596
iterations_since_restore: 150
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 58.089999999999996
  gpu_util_percent0: 0.95
  gpu_util_percent1: 0.0
  ram_util_percent: 93.05000000000001
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 30.277802653733005
  p: 28.849757291749974
policy_reward_mean:
  a: 1.0556850732829939
  p: 16.45176507144316
policy_reward_min:
  a: -11.722355493605876
  p: 5.4085699275664565
sampler_perf:
  mean_env_wait_ms: 7.573326152969652
  mean_inference_ms: 7.92794886355164
  mean_processing_ms: 2.924131648563781
time_since_restore: 1349.0119197368622
time_this_iter_s: 8.220661640167236
time_total_s: 1349.0119197368622
timestamp: 1638389661
timesteps_since_restore: 900000
timesteps_this_iter: 6000
timesteps_total: 900000
training_iteration: 150

2021-12-01 15:14:29,396 Iter 151: steps this-iter 6000 total 906000 -> 900/100000 episodes done
2021-12-01 15:14:37,417 Iter 152: steps this-iter 6000 total 912000 -> 900/100000 episodes done
2021-12-01 15:14:46,176 Iter 153: steps this-iter 6000 total 918000 -> 900/100000 episodes done
2021-12-01 15:14:54,407 Iter 154: steps this-iter 6000 total 924000 -> 900/100000 episodes done
2021-12-01 15:15:03,259 Iter 155: steps this-iter 6000 total 930000 -> 930/100000 episodes done
2021-12-01 15:15:03,267 custom_metrics: {}
date: 2021-12-01_15-15-03
done: false
episode_len_mean: 1000.0
episode_reward_max: 64.72658690696076
episode_reward_mean: 27.770942870831075
episode_reward_min: -7.850241871836495
episodes_this_iter: 30
episodes_total: 930
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3771.598
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5932997465133667
      entropy_coeff: 0.02500000037252903
      kl: 0.0027891225181519985
      model: {}
      policy_loss: -0.0004878062754869461
      total_loss: 0.05145379900932312
      vf_explained_var: 0.4483027756214142
      vf_loss: 1.335481882095337
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09692040085792542
      entropy_coeff: 1.9653500318527222
      kl: 1.0699089898480452e-06
      model: {}
      policy_loss: -5.21540641784668e-07
      total_loss: 0.115975022315979
      vf_explained_var: 0.044432684779167175
      vf_loss: 6.129161834716797
  load_time_ms: 815.096
  num_steps_sampled: 930000
  num_steps_trained: 930000
  sample_time_ms: 3707.986
  update_time_ms: 16.674
iterations_since_restore: 155
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 64.85454545454546
  gpu_util_percent0: 0.8881818181818182
  gpu_util_percent1: 0.0
  ram_util_percent: 93.76363636363635
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03643460751303889
pid: 82568
policy_reward_max:
  a: 33.04962817499216
  p: 42.9217506243264
policy_reward_mean:
  a: 0.895726410113379
  p: 24.18803723037767
policy_reward_min:
  a: -12.386844232784085
  p: 10.585220652292328
sampler_perf:
  mean_env_wait_ms: 7.564288669046111
  mean_inference_ms: 7.912944060810718
  mean_processing_ms: 2.9202597547051456
time_since_restore: 1390.9826354980469
time_this_iter_s: 8.829084873199463
time_total_s: 1390.9826354980469
timestamp: 1638389703
timesteps_since_restore: 930000
timesteps_this_iter: 6000
timesteps_total: 930000
training_iteration: 155

2021-12-01 15:15:14,232 Iter 156: steps this-iter 6000 total 936000 -> 930/100000 episodes done
2021-12-01 15:15:23,383 Iter 157: steps this-iter 6000 total 942000 -> 930/100000 episodes done
2021-12-01 15:15:31,700 Iter 158: steps this-iter 6000 total 948000 -> 930/100000 episodes done
2021-12-01 15:15:40,386 Iter 159: steps this-iter 6000 total 954000 -> 930/100000 episodes done
2021-12-01 15:15:49,716 Iter 160: steps this-iter 6000 total 960000 -> 960/100000 episodes done
2021-12-01 15:15:49,722 custom_metrics: {}
date: 2021-12-01_15-15-49
done: false
episode_len_mean: 1000.0
episode_reward_max: 74.20775973650191
episode_reward_mean: 26.454081257135794
episode_reward_min: -17.30744118673975
episodes_this_iter: 30
episodes_total: 960
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4094.364
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6083145141601562
      entropy_coeff: 0.02500000037252903
      kl: 0.0017517227679491043
      model: {}
      policy_loss: 6.12158328294754e-05
      total_loss: 0.04554516822099686
      vf_explained_var: 0.39392971992492676
      vf_loss: 1.2138361930847168
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09677448868751526
      entropy_coeff: 1.9642250537872314
      kl: 2.5379431463079527e-06
      model: {}
      policy_loss: 2.8302427381277084e-05
      total_loss: 0.184764102101326
      vf_explained_var: 0.023749083280563354
      vf_loss: 7.496452808380127
  load_time_ms: 824.496
  num_steps_sampled: 960000
  num_steps_trained: 960000
  sample_time_ms: 3878.926
  update_time_ms: 21.914
iterations_since_restore: 160
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 67.52727272727272
  gpu_util_percent0: 0.8854545454545455
  gpu_util_percent1: 0.0
  ram_util_percent: 94.58181818181819
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 29.925923343576343
  p: 49.39116504861984
policy_reward_mean:
  a: 0.8442921402889928
  p: 23.07691269597996
policy_reward_min:
  a: -13.514233110171121
  p: 5.620232501969966
sampler_perf:
  mean_env_wait_ms: 7.569893526772419
  mean_inference_ms: 7.922306302976987
  mean_processing_ms: 2.9231977404655836
time_since_restore: 1437.3904740810394
time_this_iter_s: 9.320969343185425
time_total_s: 1437.3904740810394
timestamp: 1638389749
timesteps_since_restore: 960000
timesteps_this_iter: 6000
timesteps_total: 960000
training_iteration: 160

2021-12-01 15:15:58,312 Iter 161: steps this-iter 6000 total 966000 -> 960/100000 episodes done
2021-12-01 15:16:06,631 Iter 162: steps this-iter 6000 total 972000 -> 960/100000 episodes done
2021-12-01 15:16:14,752 Iter 163: steps this-iter 6000 total 978000 -> 960/100000 episodes done
2021-12-01 15:16:22,926 Iter 164: steps this-iter 6000 total 984000 -> 960/100000 episodes done
2021-12-01 15:16:31,172 Iter 165: steps this-iter 6000 total 990000 -> 990/100000 episodes done
2021-12-01 15:16:31,178 custom_metrics: {}
date: 2021-12-01_15-16-31
done: false
episode_len_mean: 1000.0
episode_reward_max: 65.41348930420632
episode_reward_mean: 22.11164528182701
episode_reward_min: -4.345225527205851
episodes_this_iter: 30
episodes_total: 990
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4029.679
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.6205917596817017
      entropy_coeff: 0.02500000037252903
      kl: 0.003964412957429886
      model: {}
      policy_loss: -0.00039768125861883163
      total_loss: 0.038828253746032715
      vf_explained_var: 0.4340200126171112
      vf_loss: 1.0948147773742676
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09694546461105347
      entropy_coeff: 1.9630999565124512
      kl: 4.09172207582742e-06
      model: {}
      policy_loss: 8.334405720233917e-05
      total_loss: 0.19030170142650604
      vf_explained_var: 0.02259284257888794
      vf_loss: 7.610640048980713
  load_time_ms: 828.765
  num_steps_sampled: 990000
  num_steps_trained: 990000
  sample_time_ms: 3882.475
  update_time_ms: 22.602
iterations_since_restore: 165
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 56.80000000000001
  gpu_util_percent0: 0.924
  gpu_util_percent1: 0.0
  ram_util_percent: 93.02000000000001
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 34.41151392588324
  p: 50.098647747168684
policy_reward_mean:
  a: -0.362744537531783
  p: 23.562623431954233
policy_reward_min:
  a: -12.599286165941793
  p: 7.344826645900648
sampler_perf:
  mean_env_wait_ms: 7.561729665286745
  mean_inference_ms: 7.912176268467482
  mean_processing_ms: 2.9186330706107793
time_since_restore: 1478.8046810626984
time_this_iter_s: 8.241427183151245
time_total_s: 1478.8046810626984
timestamp: 1638389791
timesteps_since_restore: 990000
timesteps_this_iter: 6000
timesteps_total: 990000
training_iteration: 165

2021-12-01 15:16:39,356 Iter 166: steps this-iter 6000 total 996000 -> 990/100000 episodes done
2021-12-01 15:16:47,545 Iter 167: steps this-iter 6000 total 1002000 -> 990/100000 episodes done
2021-12-01 15:16:56,472 Iter 168: steps this-iter 6000 total 1008000 -> 990/100000 episodes done
2021-12-01 15:17:04,720 Iter 169: steps this-iter 6000 total 1014000 -> 990/100000 episodes done
2021-12-01 15:17:13,961 Iter 170: steps this-iter 6000 total 1020000 -> 1020/100000 episodes done
2021-12-01 15:17:13,966 custom_metrics: {}
date: 2021-12-01_15-17-13
done: false
episode_len_mean: 1000.0
episode_reward_max: 73.13427506102522
episode_reward_mean: 21.877618224448305
episode_reward_min: -5.91068334874601
episodes_this_iter: 30
episodes_total: 1020
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3777.828
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5558212995529175
      entropy_coeff: 0.02500000037252903
      kl: 0.0019571324810385704
      model: {}
      policy_loss: -0.0002474244683980942
      total_loss: 0.042058996856212616
      vf_explained_var: 0.4201478362083435
      vf_loss: 1.1240390539169312
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09697374701499939
      entropy_coeff: 1.9619749784469604
      kl: 1.327147288066044e-06
      model: {}
      policy_loss: 3.3561140298843384e-05
      total_loss: 0.2044374942779541
      vf_explained_var: 0.02307996153831482
      vf_loss: 7.893280982971191
  load_time_ms: 831.226
  num_steps_sampled: 1020000
  num_steps_trained: 1020000
  sample_time_ms: 3761.796
  update_time_ms: 16.797
iterations_since_restore: 170
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 68.85
  gpu_util_percent0: 0.8380000000000001
  gpu_util_percent1: 0.0
  ram_util_percent: 94.19000000000001
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 27.687401341327426
  p: 48.051228167094976
policy_reward_mean:
  a: -0.6434233010967809
  p: 24.45131142883557
policy_reward_min:
  a: -23.23084341602609
  p: 13.876016516031509
sampler_perf:
  mean_env_wait_ms: 7.557673690966581
  mean_inference_ms: 7.905277522378343
  mean_processing_ms: 2.9154463174192276
time_since_restore: 1521.4883160591125
time_this_iter_s: 9.234536170959473
time_total_s: 1521.4883160591125
timestamp: 1638389833
timesteps_since_restore: 1020000
timesteps_this_iter: 6000
timesteps_total: 1020000
training_iteration: 170

2021-12-01 15:17:25,577 Iter 171: steps this-iter 6000 total 1026000 -> 1020/100000 episodes done
2021-12-01 15:17:33,865 Iter 172: steps this-iter 6000 total 1032000 -> 1020/100000 episodes done
2021-12-01 15:17:42,051 Iter 173: steps this-iter 6000 total 1038000 -> 1020/100000 episodes done
2021-12-01 15:17:50,543 Iter 174: steps this-iter 6000 total 1044000 -> 1020/100000 episodes done
2021-12-01 15:17:59,795 Iter 175: steps this-iter 6000 total 1050000 -> 1050/100000 episodes done
2021-12-01 15:17:59,801 custom_metrics: {}
date: 2021-12-01_15-17-59
done: false
episode_len_mean: 1000.0
episode_reward_max: 47.73819976200821
episode_reward_mean: 16.963489231200075
episode_reward_min: -6.899126046599381
episodes_this_iter: 30
episodes_total: 1050
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4147.732
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.521437406539917
      entropy_coeff: 0.02500000037252903
      kl: 0.0013161331880837679
      model: {}
      policy_loss: 4.626205191016197e-05
      total_loss: 0.03544396162033081
      vf_explained_var: 0.43139755725860596
      vf_loss: 0.9686726331710815
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09697858989238739
      entropy_coeff: 1.9608500003814697
      kl: 2.3214606699184515e-06
      model: {}
      policy_loss: -2.934783697128296e-05
      total_loss: 0.13057389855384827
      vf_explained_var: 0.03536391258239746
      vf_loss: 6.415274620056152
  load_time_ms: 816.369
  num_steps_sampled: 1050000
  num_steps_trained: 1050000
  sample_time_ms: 3844.777
  update_time_ms: 17.564
iterations_since_restore: 175
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 67.26363636363637
  gpu_util_percent0: 0.8490909090909091
  gpu_util_percent1: 0.0
  ram_util_percent: 94.56363636363636
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 27.030848742749555
  p: 29.748118782677576
policy_reward_mean:
  a: 0.11179863768005736
  p: 16.51629468047999
policy_reward_min:
  a: -14.778030542748933
  p: 6.217695623084253
sampler_perf:
  mean_env_wait_ms: 7.555767592115166
  mean_inference_ms: 7.905552209518606
  mean_processing_ms: 2.9167861083282203
time_since_restore: 1567.283639907837
time_this_iter_s: 9.243586540222168
time_total_s: 1567.283639907837
timestamp: 1638389879
timesteps_since_restore: 1050000
timesteps_this_iter: 6000
timesteps_total: 1050000
training_iteration: 175

2021-12-01 15:18:08,538 Iter 176: steps this-iter 6000 total 1056000 -> 1050/100000 episodes done
2021-12-01 15:18:16,729 Iter 177: steps this-iter 6000 total 1062000 -> 1050/100000 episodes done
2021-12-01 15:18:24,947 Iter 178: steps this-iter 6000 total 1068000 -> 1050/100000 episodes done
2021-12-01 15:18:33,045 Iter 179: steps this-iter 6000 total 1074000 -> 1050/100000 episodes done
2021-12-01 15:18:41,274 Iter 180: steps this-iter 6000 total 1080000 -> 1080/100000 episodes done
2021-12-01 15:18:41,279 custom_metrics: {}
date: 2021-12-01_15-18-41
done: false
episode_len_mean: 1000.0
episode_reward_max: 53.19879264835593
episode_reward_mean: 27.399499835918398
episode_reward_min: 4.751714569109357
episodes_this_iter: 30
episodes_total: 1080
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4063.136
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5732676982879639
      entropy_coeff: 0.02500000037252903
      kl: 0.0012148784007877111
      model: {}
      policy_loss: 0.0002721911296248436
      total_loss: 0.02939346432685852
      vf_explained_var: 0.5237979888916016
      vf_loss: 0.8690592050552368
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09691163152456284
      entropy_coeff: 1.959725022315979
      kl: 3.0670094020024408e-06
      model: {}
      policy_loss: -1.54934823513031e-05
      total_loss: 0.12702079117298126
      vf_explained_var: 0.06178021430969238
      vf_loss: 6.3391289710998535
  load_time_ms: 787.059
  num_steps_sampled: 1080000
  num_steps_trained: 1080000
  sample_time_ms: 3840.641
  update_time_ms: 17.5
iterations_since_restore: 180
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 58.080000000000005
  gpu_util_percent0: 0.9440000000000002
  gpu_util_percent1: 0.0
  ram_util_percent: 93.00999999999999
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03640159767610749
pid: 82568
policy_reward_max:
  a: 51.09181597367125
  p: 34.90679224401905
policy_reward_mean:
  a: 1.5741652675775484
  p: 21.102838765608396
policy_reward_min:
  a: -11.206850395356334
  p: 4.9071285507715
sampler_perf:
  mean_env_wait_ms: 7.549799951649576
  mean_inference_ms: 7.897397790879162
  mean_processing_ms: 2.913479114790061
time_since_restore: 1608.7338223457336
time_this_iter_s: 8.225148439407349
time_total_s: 1608.7338223457336
timestamp: 1638389921
timesteps_since_restore: 1080000
timesteps_this_iter: 6000
timesteps_total: 1080000
training_iteration: 180

2021-12-01 15:18:49,589 Iter 181: steps this-iter 6000 total 1086000 -> 1080/100000 episodes done
2021-12-01 15:18:58,209 Iter 182: steps this-iter 6000 total 1092000 -> 1080/100000 episodes done
2021-12-01 15:19:07,311 Iter 183: steps this-iter 6000 total 1098000 -> 1080/100000 episodes done
2021-12-01 15:19:16,436 Iter 184: steps this-iter 6000 total 1104000 -> 1080/100000 episodes done
2021-12-01 15:19:30,134 Iter 185: steps this-iter 6000 total 1110000 -> 1110/100000 episodes done
2021-12-01 15:19:30,139 custom_metrics: {}
date: 2021-12-01_15-19-30
done: false
episode_len_mean: 1000.0
episode_reward_max: 70.60522364535996
episode_reward_mean: 26.910713324112272
episode_reward_min: -13.84116088783091
episodes_this_iter: 30
episodes_total: 1110
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4182.535
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.542884349822998
      entropy_coeff: 0.02500000037252903
      kl: 0.0012311243917793036
      model: {}
      policy_loss: -0.0002856738865375519
      total_loss: 0.0399949848651886
      vf_explained_var: 0.4311780035495758
      vf_loss: 1.0770552158355713
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09688695520162582
      entropy_coeff: 1.9586000442504883
      kl: 3.0308015084301587e-06
      model: {}
      policy_loss: -4.885159432888031e-05
      total_loss: 0.14319123327732086
      vf_explained_var: 0.05086706578731537
      vf_loss: 6.66005802154541
  load_time_ms: 970.05
  num_steps_sampled: 1110000
  num_steps_trained: 1110000
  sample_time_ms: 3837.267
  update_time_ms: 15.722
iterations_since_restore: 185
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 77.32
  gpu_util_percent0: 0.7593333333333334
  gpu_util_percent1: 0.0
  ram_util_percent: 94.93999999999998
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.0364015976761075
pid: 82568
policy_reward_max:
  a: 37.14112193360644
  p: 41.795360595868125
policy_reward_mean:
  a: 0.5923444514350125
  p: 24.54133551837235
policy_reward_min:
  a: -12.824713669738284
  p: 6.106612205592293
sampler_perf:
  mean_env_wait_ms: 7.549972076600215
  mean_inference_ms: 7.897724726876185
  mean_processing_ms: 2.9152343579511695
time_since_restore: 1657.5177764892578
time_this_iter_s: 13.689337491989136
time_total_s: 1657.5177764892578
timestamp: 1638389970
timesteps_since_restore: 1110000
timesteps_this_iter: 6000
timesteps_total: 1110000
training_iteration: 185

2021-12-01 15:19:38,433 Iter 186: steps this-iter 6000 total 1116000 -> 1110/100000 episodes done
2021-12-01 15:19:46,730 Iter 187: steps this-iter 6000 total 1122000 -> 1110/100000 episodes done
2021-12-01 15:19:54,961 Iter 188: steps this-iter 6000 total 1128000 -> 1110/100000 episodes done
2021-12-01 15:20:04,407 Iter 189: steps this-iter 6000 total 1134000 -> 1110/100000 episodes done
2021-12-01 15:20:13,287 Iter 190: steps this-iter 6000 total 1140000 -> 1140/100000 episodes done
2021-12-01 15:20:13,294 custom_metrics: {}
date: 2021-12-01_15-20-13
done: false
episode_len_mean: 1000.0
episode_reward_max: 53.21860883266997
episode_reward_mean: 20.16267162287546
episode_reward_min: -16.512687383930896
episodes_this_iter: 30
episodes_total: 1140
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 4265.912
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5273533463478088
      entropy_coeff: 0.02500000037252903
      kl: 0.0020476030185818672
      model: {}
      policy_loss: -8.538831025362015e-05
      total_loss: 0.0415453165769577
      vf_explained_var: 0.3973273038864136
      vf_loss: 1.0962908267974854
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09692293405532837
      entropy_coeff: 1.957474946975708
      kl: 3.2790562727313954e-06
      model: {}
      policy_loss: -4.2158178985118866e-05
      total_loss: 0.10524524748325348
      vf_explained_var: 0.09811018407344818
      vf_loss: 5.900232315063477
  load_time_ms: 1008.524
  num_steps_sampled: 1140000
  num_steps_trained: 1140000
  sample_time_ms: 3877.633
  update_time_ms: 16.943
iterations_since_restore: 190
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 62.36999999999999
  gpu_util_percent0: 0.861
  gpu_util_percent1: 0.0
  ram_util_percent: 93.88999999999999
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 29.323553150801438
  p: 40.443588429712136
policy_reward_mean:
  a: 0.33387037473110664
  p: 18.827190123951166
policy_reward_min:
  a: -11.399081477283898
  p: 5.120965760899845
sampler_perf:
  mean_env_wait_ms: 7.5506747411514405
  mean_inference_ms: 7.895881273078873
  mean_processing_ms: 2.91518134888771
time_since_restore: 1700.6134989261627
time_this_iter_s: 8.875259160995483
time_total_s: 1700.6134989261627
timestamp: 1638390013
timesteps_since_restore: 1140000
timesteps_this_iter: 6000
timesteps_total: 1140000
training_iteration: 190

2021-12-01 15:20:21,664 Iter 191: steps this-iter 6000 total 1146000 -> 1140/100000 episodes done
2021-12-01 15:20:29,847 Iter 192: steps this-iter 6000 total 1152000 -> 1140/100000 episodes done
2021-12-01 15:20:37,952 Iter 193: steps this-iter 6000 total 1158000 -> 1140/100000 episodes done
2021-12-01 15:20:46,104 Iter 194: steps this-iter 6000 total 1164000 -> 1140/100000 episodes done
2021-12-01 15:20:54,326 Iter 195: steps this-iter 6000 total 1170000 -> 1170/100000 episodes done
2021-12-01 15:20:54,333 custom_metrics: {}
date: 2021-12-01_15-20-54
done: false
episode_len_mean: 1000.0
episode_reward_max: 63.85115719338448
episode_reward_mean: 23.01187225133294
episode_reward_min: -4.834122142416756
episodes_this_iter: 30
episodes_total: 1170
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3789.649
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.48284533619880676
      entropy_coeff: 0.02500000037252903
      kl: 0.0031562182120978832
      model: {}
      policy_loss: 0.0008309921249747276
      total_loss: 0.02678396739065647
      vf_explained_var: 0.40935182571411133
      vf_loss: 0.7604823112487793
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09688207507133484
      entropy_coeff: 1.9563499689102173
      kl: 1.9323749711475102e-06
      model: {}
      policy_loss: -2.5469809770584106e-05
      total_loss: 0.09573192149400711
      vf_explained_var: 0.10023319721221924
      vf_loss: 5.705852508544922
  load_time_ms: 839.081
  num_steps_sampled: 1170000
  num_steps_trained: 1170000
  sample_time_ms: 3748.048
  update_time_ms: 16.681
iterations_since_restore: 195
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 56.55
  gpu_util_percent0: 0.914
  gpu_util_percent1: 0.0
  ram_util_percent: 93.24999999999999
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 37.16691962223424
  p: 38.07700133185933
policy_reward_mean:
  a: 0.647023307723781
  p: 20.42377902043805
policy_reward_min:
  a: -11.70782326124183
  p: 6.501050417704893
sampler_perf:
  mean_env_wait_ms: 7.541040783147399
  mean_inference_ms: 7.881503539074261
  mean_processing_ms: 2.9099305059166403
time_since_restore: 1741.6195108890533
time_this_iter_s: 8.217264413833618
time_total_s: 1741.6195108890533
timestamp: 1638390054
timesteps_since_restore: 1170000
timesteps_this_iter: 6000
timesteps_total: 1170000
training_iteration: 195

2021-12-01 15:21:02,458 Iter 196: steps this-iter 6000 total 1176000 -> 1170/100000 episodes done
2021-12-01 15:21:10,774 Iter 197: steps this-iter 6000 total 1182000 -> 1170/100000 episodes done
2021-12-01 15:21:22,238 Iter 198: steps this-iter 6000 total 1188000 -> 1170/100000 episodes done
2021-12-01 15:21:32,925 Iter 199: steps this-iter 6000 total 1194000 -> 1170/100000 episodes done
2021-12-01 15:21:43,041 Iter 200: steps this-iter 6000 total 1200000 -> 1200/100000 episodes done
2021-12-01 15:21:43,046 custom_metrics: {}
date: 2021-12-01_15-21-43
done: false
episode_len_mean: 1000.0
episode_reward_max: 65.41247997042441
episode_reward_mean: 21.626878409320227
episode_reward_min: -18.468464122716664
episodes_this_iter: 30
episodes_total: 1200
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3815.026
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5564655065536499
      entropy_coeff: 0.02500000037252903
      kl: 0.0009632572764530778
      model: {}
      policy_loss: 0.00045532453805208206
      total_loss: 0.0267946720123291
      vf_explained_var: 0.5512598752975464
      vf_loss: 0.805019736289978
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09685125946998596
      entropy_coeff: 1.9552249908447266
      kl: 1.768795868883899e-06
      model: {}
      policy_loss: 1.9492581486701965e-05
      total_loss: 0.09420641511678696
      vf_explained_var: 0.05485197901725769
      vf_loss: 5.671058177947998
  load_time_ms: 1194.869
  num_steps_sampled: 1200000
  num_steps_trained: 1200000
  sample_time_ms: 3925.31
  update_time_ms: 16.574
iterations_since_restore: 200
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 68.71818181818182
  gpu_util_percent0: 0.7981818181818181
  gpu_util_percent1: 0.0
  ram_util_percent: 94.4909090909091
  vram_util_percent0: 0.8753970414738178
  vram_util_percent1: 0.03649237472766885
pid: 82568
policy_reward_max:
  a: 33.021822484086535
  p: 40.110711354597726
policy_reward_mean:
  a: 0.7906685854080174
  p: 18.46420406768831
policy_reward_min:
  a: -13.868856010149287
  p: 2.919434506865153
sampler_perf:
  mean_env_wait_ms: 7.555684069181001
  mean_inference_ms: 7.90334179629022
  mean_processing_ms: 2.912585048275481
time_since_restore: 1790.2924773693085
time_this_iter_s: 10.109183311462402
time_total_s: 1790.2924773693085
timestamp: 1638390103
timesteps_since_restore: 1200000
timesteps_this_iter: 6000
timesteps_total: 1200000
training_iteration: 200

2021-12-01 15:21:46,636 >> Wrote dense logs to: phase2/dense_logs/logs_0000000001200000
2021-12-01 15:21:54,780 Iter 201: steps this-iter 6000 total 1206000 -> 1200/100000 episodes done
2021-12-01 15:22:03,332 Iter 202: steps this-iter 6000 total 1212000 -> 1200/100000 episodes done
2021-12-01 15:22:24,201 Iter 203: steps this-iter 6000 total 1218000 -> 1200/100000 episodes done
2021-12-01 15:22:33,041 Iter 204: steps this-iter 6000 total 1224000 -> 1200/100000 episodes done
2021-12-01 15:22:47,136 Iter 205: steps this-iter 6000 total 1230000 -> 1230/100000 episodes done
2021-12-01 15:22:47,144 custom_metrics: {}
date: 2021-12-01_15-22-47
done: false
episode_len_mean: 1000.0
episode_reward_max: 48.44257463819401
episode_reward_mean: 25.421868606530122
episode_reward_min: -10.073449495999823
episodes_this_iter: 30
episodes_total: 1230
experiment_id: 2c2efc925a5a4609aa433d7570b84450
hostname: cds-gpu1
info:
  grad_time_ms: 3808.304
  learner:
    a:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 0.5619891285896301
      entropy_coeff: 0.02500000037252903
      kl: 0.001983596943318844
      model: {}
      policy_loss: 0.00027644820511341095
      total_loss: 0.03281015902757645
      vf_explained_var: 0.5001628994941711
      vf_loss: 0.9316688179969788
    p:
      cur_kl_coeff: 0.0
      cur_lr: 9.999999747378752e-05
      entropy: 0.09692412614822388
      entropy_coeff: 1.9541000127792358
      kl: 1.538332753625582e-06
      model: {}
      policy_loss: -8.89413058757782e-06
      total_loss: 0.06268201768398285
      vf_explained_var: 0.10194635391235352
      vf_loss: 5.041806697845459
  load_time_ms: 2667.504
  num_steps_sampled: 1230000
  num_steps_trained: 1230000
  sample_time_ms: 4395.899
  update_time_ms: 16.472
iterations_since_restore: 205
node_ip: 128.84.217.23
num_healthy_workers: 15
off_policy_estimator: {}
perf:
  cpu_util_percent: 47.69411764705882
  gpu_util_percent0: 0.9147058823529411
  gpu_util_percent1: 0.0
  ram_util_percent: 95.3
  vram_util_percent0: 0.8753970414738179
  vram_util_percent1: 0.0371278140885984
pid: 82568
policy_reward_max:
  a: 32.05573235207809
  p: 27.56725182575739
policy_reward_mean:
  a: 1.78818983725605
  p: 18.26910925750615
policy_reward_min:
  a: -10.813078288676522
  p: 3.332746823678121
sampler_perf:
  mean_env_wait_ms: 7.6449395501485595
  mean_inference_ms: 7.8947006715529975
  mean_processing_ms: 2.9120418084039628
time_since_restore: 1850.6793675422668
time_this_iter_s: 14.073408842086792
time_total_s: 1850.6793675422668
timestamp: 1638390167
timesteps_since_restore: 1230000
timesteps_this_iter: 6000
timesteps_total: 1230000
training_iteration: 205

2021-12-01 15:22:55,434 Iter 206: steps this-iter 6000 total 1236000 -> 1230/100000 episodes done
2021-12-01 15:23:03,834 Iter 207: steps this-iter 6000 total 1242000 -> 1230/100000 episodes done
2021-12-01 15:23:12,270 Iter 208: steps this-iter 6000 total 1248000 -> 1230/100000 episodes done
1 GPUs are available.
1 GPUs are available.
Traceback (most recent call last):
  File "training_script.py", line 306, in <module>
    result = trainer.train()
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 502, in train
    raise e
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 491, in train
    result = Trainable.train(self)
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/tune/trainable.py", line 261, in train
    result = self._train()
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 161, in _train
    res = self.collect_metrics()
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 899, in collect_metrics
    selected_workers=selected_workers)
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/optimizers/policy_optimizer.py", line 104, in collect_metrics
    timeout_seconds=timeout_seconds)
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/evaluation/metrics.py", line 71, in collect_episodes
    metric_lists = ray_get_and_free(collected)
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/rllib/utils/memory.py", line 29, in ray_get_and_free
    result = ray.get(object_ids)
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/worker.py", line 1513, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RayOutOfMemoryError): [36mray::RolloutWorker[39m (pid=82686, ip=128.84.217.23)
  File "python/ray/_raylet.pyx", line 415, in ray._raylet.execute_task
  File "/home/ew423/anaconda3/envs/rllib-training/lib/python3.7/site-packages/ray/memory_monitor.py", line 120, in raise_if_low_memory
    self.error_threshold))
ray.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node cds-gpu1 is used (30.08 / 31.33 GB). The top 10 memory consumers are:

PID	MEM	COMMAND
82568	2.34GiB	python training_script.py --run-dir phase2
130124	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
130108	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
130091	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
130080	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
130032	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
129969	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
129953	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
129952	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1
129951	2.2GiB	python main.py --env-name BreakoutNoFrameskip-v4 --algo trpo --use-gae --lr 2.5e-4 --clip-param 0.1

In addition, up to 0.86 GiB of shared memory is currently being used by the Ray object store. You can set the object store size with the `object_store_memory` parameter when starting Ray.
---
--- Tip: Use the `ray memory` command to list active objects in the cluster.
---
